{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10776\n",
      "108\n",
      "Finished!\n",
      "512\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.1781377  | loss_wrt: 0.17256  | loss_unl: 0.19127  | learning_rate: 0.00050\n",
      "OA: 0.7773  | AA:  0.6040  | Kappa:  0.7450  | Time: 18.3\n",
      "[100,   201] loss: 0.2639935  | loss_wrt: 0.07480  | loss_unl: 0.10359  | learning_rate: 0.00050\n",
      "OA: 0.8528  | AA:  0.7184  | Kappa:  0.8312  | Time: 16.6\n",
      "[150,   301] loss: 0.1633430  | loss_wrt: 0.08098  | loss_unl: 0.10975  | learning_rate: 0.00050\n",
      "OA: 0.8530  | AA:  0.7354  | Kappa:  0.8319  | Time: 16.5\n",
      "[200,   401] loss: 0.0817260  | loss_wrt: 0.03255  | loss_unl: 0.06644  | learning_rate: 0.00050\n",
      "OA: 0.8472  | AA:  0.7432  | Kappa:  0.8246  | Time: 16.6\n",
      "[250,   501] loss: 0.0994483  | loss_wrt: 0.03112  | loss_unl: 0.05506  | learning_rate: 0.00050\n",
      "OA: 0.8631  | AA:  0.7447  | Kappa:  0.8437  | Time: 16.5\n",
      "[300,   601] loss: 0.0639250  | loss_wrt: 0.03752  | loss_unl: 0.05882  | learning_rate: 0.00050\n",
      "OA: 0.8084  | AA:  0.7111  | Kappa:  0.7768  | Time: 16.5\n",
      "[350,   701] loss: 0.0544738  | loss_wrt: 0.02382  | loss_unl: 0.04511  | learning_rate: 0.00050\n",
      "OA: 0.8861  | AA:  0.7752  | Kappa:  0.8693  | Time: 16.6\n",
      "[400,   801] loss: 0.0567178  | loss_wrt: 0.02178  | loss_unl: 0.04029  | learning_rate: 0.00050\n",
      "OA: 0.8708  | AA:  0.7603  | Kappa:  0.8519  | Time: 16.6\n",
      "[450,   901] loss: 0.0426319  | loss_wrt: 0.01114  | loss_unl: 0.03252  | learning_rate: 0.00050\n",
      "OA: 0.8930  | AA:  0.7748  | Kappa:  0.8774  | Time: 16.6\n",
      "[500,  1001] loss: 0.0270933  | loss_wrt: 0.01366  | loss_unl: 0.02343  | learning_rate: 0.00050\n",
      "OA: 0.8998  | AA:  0.7878  | Kappa:  0.8853  | Time: 16.5\n",
      "[550,  1101] loss: 0.0962617  | loss_wrt: 0.01603  | loss_unl: 0.04872  | learning_rate: 0.00045\n",
      "OA: 0.8866  | AA:  0.7777  | Kappa:  0.8698  | Time: 16.6\n",
      "[600,  1201] loss: 0.0516613  | loss_wrt: 0.01325  | loss_unl: 0.02441  | learning_rate: 0.00045\n",
      "OA: 0.9014  | AA:  0.7961  | Kappa:  0.8872  | Time: 16.5\n",
      "[650,  1301] loss: 0.0253009  | loss_wrt: 0.01223  | loss_unl: 0.02270  | learning_rate: 0.00045\n",
      "OA: 0.8923  | AA:  0.7841  | Kappa:  0.8764  | Time: 16.6\n",
      "[700,  1401] loss: 0.0204292  | loss_wrt: 0.00580  | loss_unl: 0.01489  | learning_rate: 0.00045\n",
      "OA: 0.8997  | AA:  0.7946  | Kappa:  0.8849  | Time: 16.5\n",
      "[750,  1501] loss: 0.0138034  | loss_wrt: 0.00746  | loss_unl: 0.01479  | learning_rate: 0.00045\n",
      "OA: 0.9006  | AA:  0.7972  | Kappa:  0.8860  | Time: 16.6\n",
      "[800,  1601] loss: 0.0180947  | loss_wrt: 0.00723  | loss_unl: 0.01453  | learning_rate: 0.00045\n",
      "OA: 0.8900  | AA:  0.7793  | Kappa:  0.8737  | Time: 16.6\n",
      "[850,  1701] loss: 0.0174840  | loss_wrt: 0.00453  | loss_unl: 0.01253  | learning_rate: 0.00045\n",
      "OA: 0.9060  | AA:  0.8006  | Kappa:  0.8924  | Time: 16.5\n",
      "[900,  1801] loss: 0.0196077  | loss_wrt: 0.00993  | loss_unl: 0.01611  | learning_rate: 0.00045\n",
      "OA: 0.8914  | AA:  0.7743  | Kappa:  0.8753  | Time: 16.5\n",
      "[950,  1901] loss: 0.0295346  | loss_wrt: 0.00470  | loss_unl: 0.01029  | learning_rate: 0.00045\n",
      "OA: 0.9057  | AA:  0.7962  | Kappa:  0.8920  | Time: 16.6\n",
      "[1000,  2001] loss: 0.0081344  | loss_wrt: 0.00566  | loss_unl: 0.01165  | learning_rate: 0.00045\n",
      "OA: 0.9149  | AA:  0.8036  | Kappa:  0.9027  | Time: 16.6\n",
      "[1050,  2101] loss: 0.0195137  | loss_wrt: 0.01820  | loss_unl: 0.00778  | learning_rate: 0.00041\n",
      "OA: 0.9010  | AA:  0.7825  | Kappa:  0.8865  | Time: 16.6\n",
      "[1100,  2201] loss: 0.0090094  | loss_wrt: 0.00440  | loss_unl: 0.01043  | learning_rate: 0.00041\n",
      "OA: 0.8843  | AA:  0.7865  | Kappa:  0.8677  | Time: 16.6\n",
      "[1150,  2301] loss: 0.0188579  | loss_wrt: 0.01714  | loss_unl: 0.01181  | learning_rate: 0.00041\n",
      "OA: 0.8910  | AA:  0.7721  | Kappa:  0.8749  | Time: 16.6\n",
      "[1200,  2401] loss: 0.0112193  | loss_wrt: 0.01034  | loss_unl: 0.00772  | learning_rate: 0.00041\n",
      "OA: 0.9048  | AA:  0.7964  | Kappa:  0.8909  | Time: 16.6\n",
      "[1250,  2501] loss: 0.0098996  | loss_wrt: 0.00288  | loss_unl: 0.00939  | learning_rate: 0.00041\n",
      "OA: 0.9032  | AA:  0.7909  | Kappa:  0.8890  | Time: 16.6\n",
      "[1300,  2601] loss: 0.0901202  | loss_wrt: 0.00963  | loss_unl: 0.01518  | learning_rate: 0.00041\n",
      "OA: 0.9108  | AA:  0.7992  | Kappa:  0.8978  | Time: 16.6\n",
      "[1350,  2701] loss: 0.0232351  | loss_wrt: 0.00756  | loss_unl: 0.01094  | learning_rate: 0.00041\n",
      "OA: 0.9056  | AA:  0.7851  | Kappa:  0.8920  | Time: 16.6\n",
      "[1400,  2801] loss: 0.0419368  | loss_wrt: 0.00484  | loss_unl: 0.01128  | learning_rate: 0.00041\n",
      "OA: 0.9046  | AA:  0.8007  | Kappa:  0.8907  | Time: 16.6\n",
      "[1450,  2901] loss: 0.0069140  | loss_wrt: 0.00329  | loss_unl: 0.00789  | learning_rate: 0.00041\n",
      "OA: 0.8936  | AA:  0.7948  | Kappa:  0.8781  | Time: 16.6\n",
      "[1500,  3001] loss: 0.0183429  | loss_wrt: 0.00323  | loss_unl: 0.01656  | learning_rate: 0.00041\n",
      "OA: 0.9084  | AA:  0.8161  | Kappa:  0.8951  | Time: 16.6\n",
      "[1550,  3101] loss: 0.0052901  | loss_wrt: 0.00612  | loss_unl: 0.00524  | learning_rate: 0.00036\n",
      "OA: 0.9032  | AA:  0.7933  | Kappa:  0.8890  | Time: 16.6\n",
      "[1600,  3201] loss: 0.0043908  | loss_wrt: 0.00152  | loss_unl: 0.00485  | learning_rate: 0.00036\n",
      "OA: 0.9037  | AA:  0.7956  | Kappa:  0.8895  | Time: 16.6\n",
      "[1650,  3301] loss: 0.0237242  | loss_wrt: 0.00461  | loss_unl: 0.00617  | learning_rate: 0.00036\n",
      "OA: 0.9025  | AA:  0.7867  | Kappa:  0.8883  | Time: 16.6\n",
      "[1700,  3401] loss: 0.0066605  | loss_wrt: 0.00166  | loss_unl: 0.00541  | learning_rate: 0.00036\n",
      "OA: 0.8792  | AA:  0.7681  | Kappa:  0.8618  | Time: 16.6\n",
      "[1750,  3501] loss: 0.0042604  | loss_wrt: 0.00178  | loss_unl: 0.00483  | learning_rate: 0.00036\n",
      "OA: 0.8854  | AA:  0.7702  | Kappa:  0.8689  | Time: 16.6\n",
      "[1800,  3601] loss: 0.0146670  | loss_wrt: 0.00329  | loss_unl: 0.00638  | learning_rate: 0.00036\n",
      "OA: 0.8993  | AA:  0.7909  | Kappa:  0.8845  | Time: 16.6\n",
      "[1850,  3701] loss: 0.0049272  | loss_wrt: 0.00178  | loss_unl: 0.00594  | learning_rate: 0.00036\n",
      "OA: 0.9051  | AA:  0.7982  | Kappa:  0.8911  | Time: 16.6\n",
      "[1900,  3801] loss: 0.0037118  | loss_wrt: 0.00217  | loss_unl: 0.00458  | learning_rate: 0.00036\n",
      "OA: 0.9062  | AA:  0.7947  | Kappa:  0.8924  | Time: 16.6\n",
      "[1950,  3901] loss: 0.0042999  | loss_wrt: 0.00217  | loss_unl: 0.00521  | learning_rate: 0.00036\n",
      "OA: 0.8972  | AA:  0.7922  | Kappa:  0.8822  | Time: 16.6\n",
      "[2000,  4001] loss: 0.0062431  | loss_wrt: 0.00170  | loss_unl: 0.00463  | learning_rate: 0.00036\n",
      "OA: 0.9041  | AA:  0.8008  | Kappa:  0.8900  | Time: 16.6\n",
      "Finished Training\n",
      "model saved\n",
      "[0.         0.89126853 0.87375887 0.91542289 0.78832117 0.97741935\n",
      " 1.         1.         0.41176471 0.65859564 0.97412554 0.86904762\n",
      " 0.90804598 0.99162791 0.99085366 0.51898734]\n",
      "0.9017221584385764 0.7980774498274779 0.8872654722006545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([256, 200, 31, 31]) torch.Size([256, 200, 31, 31])\n",
      "=> all bands acc: 0.799\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: -3.48 | loss:0.803 | 100 bands | 7.6s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: -3.74 | loss:0.791 | 100 bands | 4.4s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -3.85 | loss:0.800 | 100 bands | 4.4s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: -3.82 | loss:0.801 | 100 bands | 4.4s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -3.91 | loss:0.800 | 100 bands | 4.5s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: -3.88 | loss:0.786 | 100 bands | 4.5s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: -4.04 | loss:0.779 | 100 bands | 4.6s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: -3.93 | loss:0.790 | 100 bands | 4.5s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: -3.91 | loss:0.791 | 100 bands | 4.5s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: -4.09 | loss:0.793 | 100 bands | 4.6s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: -3.86 | loss:0.782 | 100 bands | 4.5s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: -3.82 | loss:0.785 | 100 bands | 4.5s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: -3.73 | loss:0.787 | 100 bands | 4.5s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: -3.72 | loss:0.781 | 100 bands | 4.6s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: -3.69 | loss:0.785 | 100 bands | 4.6s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: -3.50 | loss:0.793 | 100 bands | 4.5s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: -3.46 | loss:0.776 | 100 bands | 4.5s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: -3.53 | loss:0.785 | 100 bands | 4.6s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: -3.52 | loss:0.778 | 100 bands | 4.6s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: -3.44 | loss:0.781 | 100 bands | 4.6s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: -3.47 | loss:0.781 | 100 bands | 4.7s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: -3.59 | loss:0.785 | 100 bands | 4.7s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: -3.83 | loss:0.779 | 100 bands | 4.8s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: -3.53 | loss:0.778 | 100 bands | 4.7s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: -3.26 | loss:0.765 | 100 bands | 4.6s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: -3.02 | loss:0.783 | 100 bands | 4.6s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: -3.00 | loss:0.777 | 100 bands | 4.7s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: -3.10 | loss:0.778 | 100 bands | 4.7s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: -2.99 | loss:0.769 | 100 bands | 4.6s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: -2.96 | loss:0.761 | 100 bands | 4.6s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: -2.85 | loss:0.753 | 100 bands | 4.6s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: -2.69 | loss:0.782 | 100 bands | 4.6s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: -2.79 | loss:0.790 | 100 bands | 4.6s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: -2.54 | loss:0.772 | 100 bands | 4.6s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: -2.58 | loss:0.767 | 100 bands | 4.7s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: -2.60 | loss:0.766 | 100 bands | 4.8s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: -2.50 | loss:0.765 | 100 bands | 4.7s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: -2.49 | loss:0.760 | 100 bands | 4.7s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: -2.67 | loss:0.764 | 100 bands | 4.8s\n",
      "r_max, 0.7543090606995975\n",
      "Done\n",
      "time :187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-22 13:33:44.141266: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-22 13:33:44.144114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-22 13:33:44.144273: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-22 13:33:44.580067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-22 13:33:44.580164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-22 13:33:44.580213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-22 13:33:44.580406: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda:0\n",
      "Start training...\n",
      "[25,   101] loss: 1.1758401  | loss_wrt: 0.14569  | loss_unl: 0.15034  | learning_rate: 0.00100\n",
      "OA: 0.9209  | AA:  0.7646  | Kappa:  0.9093  | Time: 18.0\n",
      "[50,   201] loss: 0.1186256  | loss_wrt: 0.05307  | loss_unl: 0.06664  | learning_rate: 0.00090\n",
      "OA: 0.9512  | AA:  0.8715  | Kappa:  0.9442  | Time: 16.2\n",
      "[75,   301] loss: 0.0538994  | loss_wrt: 0.03029  | loss_unl: 0.03858  | learning_rate: 0.00081\n",
      "OA: 0.9603  | AA:  0.8835  | Kappa:  0.9546  | Time: 16.2\n",
      "[100,   401] loss: 0.0297122  | loss_wrt: 0.01926  | loss_unl: 0.02670  | learning_rate: 0.00073\n",
      "OA: 0.9676  | AA:  0.8760  | Kappa:  0.9630  | Time: 16.2\n",
      "[125,   501] loss: 0.0200981  | loss_wrt: 0.01131  | loss_unl: 0.01672  | learning_rate: 0.00066\n",
      "OA: 0.9680  | AA:  0.8905  | Kappa:  0.9634  | Time: 16.2\n",
      "[150,   601] loss: 0.0134466  | loss_wrt: 0.01058  | loss_unl: 0.01328  | learning_rate: 0.00059\n",
      "OA: 0.9657  | AA:  0.8667  | Kappa:  0.9608  | Time: 16.2\n",
      "[175,   701] loss: 0.0373018  | loss_wrt: 0.01503  | loss_unl: 0.01776  | learning_rate: 0.00053\n",
      "OA: 0.9683  | AA:  0.9004  | Kappa:  0.9638  | Time: 16.2\n",
      "[200,   801] loss: 0.0126741  | loss_wrt: 0.00705  | loss_unl: 0.00992  | learning_rate: 0.00048\n",
      "OA: 0.9708  | AA:  0.9040  | Kappa:  0.9667  | Time: 16.3\n",
      "[225,   901] loss: 0.0086703  | loss_wrt: 0.00561  | loss_unl: 0.00930  | learning_rate: 0.00043\n",
      "OA: 0.9706  | AA:  0.9051  | Kappa:  0.9665  | Time: 16.3\n",
      "[250,  1001] loss: 0.0065761  | loss_wrt: 0.00411  | loss_unl: 0.00685  | learning_rate: 0.00039\n",
      "OA: 0.9712  | AA:  0.9052  | Kappa:  0.9671  | Time: 16.3\n",
      "[275,  1101] loss: 0.0053104  | loss_wrt: 0.00351  | loss_unl: 0.00570  | learning_rate: 0.00035\n",
      "OA: 0.9711  | AA:  0.8992  | Kappa:  0.9670  | Time: 16.3\n",
      "[300,  1201] loss: 0.0044724  | loss_wrt: 0.00320  | loss_unl: 0.00428  | learning_rate: 0.00031\n",
      "OA: 0.9705  | AA:  0.9005  | Kappa:  0.9663  | Time: 16.3\n",
      "[325,  1301] loss: 0.0036908  | loss_wrt: 0.00282  | loss_unl: 0.00398  | learning_rate: 0.00028\n",
      "OA: 0.9719  | AA:  0.8951  | Kappa:  0.9679  | Time: 16.3\n",
      "[350,  1401] loss: 0.0031834  | loss_wrt: 0.00222  | loss_unl: 0.00326  | learning_rate: 0.00025\n",
      "OA: 0.9715  | AA:  0.8795  | Kappa:  0.9675  | Time: 16.2\n",
      "[375,  1501] loss: 0.0027094  | loss_wrt: 0.00200  | loss_unl: 0.00281  | learning_rate: 0.00023\n",
      "OA: 0.9716  | AA:  0.8789  | Kappa:  0.9676  | Time: 16.3\n",
      "[400,  1601] loss: 0.0023500  | loss_wrt: 0.00168  | loss_unl: 0.00218  | learning_rate: 0.00021\n",
      "OA: 0.9712  | AA:  0.8724  | Kappa:  0.9671  | Time: 16.3\n",
      "[425,  1701] loss: 0.0020840  | loss_wrt: 0.00144  | loss_unl: 0.00232  | learning_rate: 0.00019\n",
      "OA: 0.9705  | AA:  0.8764  | Kappa:  0.9663  | Time: 16.3\n",
      "[450,  1801] loss: 0.0017594  | loss_wrt: 0.00122  | loss_unl: 0.00232  | learning_rate: 0.00017\n",
      "OA: 0.9711  | AA:  0.8701  | Kappa:  0.9670  | Time: 16.3\n",
      "[475,  1901] loss: 0.0015441  | loss_wrt: 0.00101  | loss_unl: 0.00126  | learning_rate: 0.00015\n",
      "OA: 0.9718  | AA:  0.8820  | Kappa:  0.9678  | Time: 16.3\n",
      "[500,  2001] loss: 0.0013966  | loss_wrt: 0.00117  | loss_unl: 0.00112  | learning_rate: 0.00014\n",
      "OA: 0.9710  | AA:  0.8829  | Kappa:  0.9668  | Time: 16.3\n",
      "Finished Training\n",
      "(8710, 2)\n",
      "[0.51282051 0.95881384 0.99432624 0.99502488 0.93430657 0.99516129\n",
      " 0.70833333 1.         0.52941176 0.94794189 0.99760422 0.93452381\n",
      " 0.97126437 0.99813953 0.92682927 0.72151899]\n",
      "0.9709529276693456 0.8828762811805636 0.9668483244234529\n",
      "(21025, 2)\n",
      "10776\n",
      "108\n",
      "Finished!\n",
      "512\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.4404046  | loss_wrt: 0.15415  | loss_unl: 0.18413  | learning_rate: 0.00050\n",
      "OA: 0.7154  | AA:  0.5512  | Kappa:  0.6746  | Time: 55.8\n",
      "[100,   201] loss: 0.3406643  | loss_wrt: 0.11249  | loss_unl: 0.13776  | learning_rate: 0.00050\n",
      "OA: 0.7915  | AA:  0.6713  | Kappa:  0.7627  | Time: 53.9\n",
      "[150,   301] loss: 0.1958805  | loss_wrt: 0.09249  | loss_unl: 0.10507  | learning_rate: 0.00050\n",
      "OA: 0.8633  | AA:  0.8073  | Kappa:  0.8448  | Time: 53.9\n",
      "[200,   401] loss: 0.1343908  | loss_wrt: 0.08400  | loss_unl: 0.08743  | learning_rate: 0.00050\n",
      "OA: 0.8223  | AA:  0.7489  | Kappa:  0.7954  | Time: 54.0\n",
      "[250,   501] loss: 0.0735833  | loss_wrt: 0.03414  | loss_unl: 0.05371  | learning_rate: 0.00050\n",
      "OA: 0.8685  | AA:  0.8152  | Kappa:  0.8506  | Time: 54.0\n",
      "[300,   601] loss: 0.0786657  | loss_wrt: 0.03022  | loss_unl: 0.05192  | learning_rate: 0.00050\n",
      "OA: 0.8821  | AA:  0.8301  | Kappa:  0.8659  | Time: 54.8\n",
      "[350,   701] loss: 0.1332941  | loss_wrt: 0.03859  | loss_unl: 0.06378  | learning_rate: 0.00050\n",
      "OA: 0.8652  | AA:  0.8231  | Kappa:  0.8471  | Time: 55.3\n",
      "[400,   801] loss: 0.0973147  | loss_wrt: 0.03446  | loss_unl: 0.06034  | learning_rate: 0.00050\n",
      "OA: 0.8835  | AA:  0.8235  | Kappa:  0.8675  | Time: 54.1\n",
      "[450,   901] loss: 0.0594206  | loss_wrt: 0.02094  | loss_unl: 0.03891  | learning_rate: 0.00050\n",
      "OA: 0.8835  | AA:  0.8336  | Kappa:  0.8676  | Time: 53.9\n",
      "[500,  1001] loss: 0.0439135  | loss_wrt: 0.01599  | loss_unl: 0.04255  | learning_rate: 0.00050\n",
      "OA: 0.8892  | AA:  0.8266  | Kappa:  0.8739  | Time: 54.1\n",
      "[550,  1101] loss: 0.0762075  | loss_wrt: 0.01992  | loss_unl: 0.04192  | learning_rate: 0.00045\n",
      "OA: 0.8850  | AA:  0.8197  | Kappa:  0.8691  | Time: 54.1\n",
      "[600,  1201] loss: 0.0354040  | loss_wrt: 0.01711  | loss_unl: 0.02743  | learning_rate: 0.00045\n",
      "OA: 0.8902  | AA:  0.8385  | Kappa:  0.8752  | Time: 54.2\n",
      "[650,  1301] loss: 0.0474524  | loss_wrt: 0.01741  | loss_unl: 0.02949  | learning_rate: 0.00045\n",
      "OA: 0.8850  | AA:  0.8479  | Kappa:  0.8696  | Time: 54.1\n",
      "[700,  1401] loss: 0.0609324  | loss_wrt: 0.01470  | loss_unl: 0.02570  | learning_rate: 0.00045\n",
      "OA: 0.8939  | AA:  0.8484  | Kappa:  0.8793  | Time: 53.9\n",
      "[750,  1501] loss: 0.0174004  | loss_wrt: 0.00738  | loss_unl: 0.02069  | learning_rate: 0.00045\n",
      "OA: 0.9003  | AA:  0.8472  | Kappa:  0.8866  | Time: 54.0\n",
      "[800,  1601] loss: 0.0132118  | loss_wrt: 0.00490  | loss_unl: 0.01389  | learning_rate: 0.00045\n",
      "OA: 0.9003  | AA:  0.8537  | Kappa:  0.8866  | Time: 54.1\n",
      "[850,  1701] loss: 0.0179796  | loss_wrt: 0.02136  | loss_unl: 0.02859  | learning_rate: 0.00045\n",
      "OA: 0.8976  | AA:  0.8329  | Kappa:  0.8836  | Time: 54.0\n",
      "[900,  1801] loss: 0.0217037  | loss_wrt: 0.00726  | loss_unl: 0.01484  | learning_rate: 0.00045\n",
      "OA: 0.8990  | AA:  0.8484  | Kappa:  0.8851  | Time: 54.0\n",
      "[950,  1901] loss: 0.0112121  | loss_wrt: 0.00376  | loss_unl: 0.01229  | learning_rate: 0.00045\n",
      "OA: 0.8978  | AA:  0.8571  | Kappa:  0.8837  | Time: 54.1\n",
      "[1000,  2001] loss: 0.0074266  | loss_wrt: 0.00375  | loss_unl: 0.01106  | learning_rate: 0.00045\n",
      "OA: 0.8997  | AA:  0.8510  | Kappa:  0.8858  | Time: 53.9\n",
      "[1050,  2101] loss: 0.0081735  | loss_wrt: 0.00366  | loss_unl: 0.00752  | learning_rate: 0.00041\n",
      "OA: 0.9024  | AA:  0.8464  | Kappa:  0.8889  | Time: 54.0\n",
      "[1100,  2201] loss: 0.0092496  | loss_wrt: 0.00339  | loss_unl: 0.00742  | learning_rate: 0.00041\n",
      "OA: 0.8972  | AA:  0.8498  | Kappa:  0.8831  | Time: 54.1\n",
      "[1150,  2301] loss: 0.0053734  | loss_wrt: 0.00202  | loss_unl: 0.00529  | learning_rate: 0.00041\n",
      "OA: 0.8661  | AA:  0.8248  | Kappa:  0.8479  | Time: 53.9\n",
      "[1200,  2401] loss: 0.0145906  | loss_wrt: 0.00511  | loss_unl: 0.00854  | learning_rate: 0.00041\n",
      "OA: 0.8899  | AA:  0.8237  | Kappa:  0.8748  | Time: 54.0\n",
      "[1250,  2501] loss: 0.0098335  | loss_wrt: 0.00287  | loss_unl: 0.00536  | learning_rate: 0.00041\n",
      "OA: 0.9014  | AA:  0.8453  | Kappa:  0.8878  | Time: 54.0\n",
      "[1300,  2601] loss: 0.0150125  | loss_wrt: 0.00601  | loss_unl: 0.00830  | learning_rate: 0.00041\n",
      "OA: 0.8987  | AA:  0.8444  | Kappa:  0.8848  | Time: 53.9\n",
      "[1350,  2701] loss: 0.0219153  | loss_wrt: 0.01292  | loss_unl: 0.00664  | learning_rate: 0.00041\n",
      "OA: 0.8989  | AA:  0.8620  | Kappa:  0.8850  | Time: 53.9\n",
      "[1400,  2801] loss: 0.0053036  | loss_wrt: 0.00198  | loss_unl: 0.00551  | learning_rate: 0.00041\n",
      "OA: 0.8999  | AA:  0.8456  | Kappa:  0.8861  | Time: 54.1\n",
      "[1450,  2901] loss: 0.0185539  | loss_wrt: 0.00425  | loss_unl: 0.00666  | learning_rate: 0.00041\n",
      "OA: 0.8891  | AA:  0.8365  | Kappa:  0.8739  | Time: 53.9\n",
      "[1500,  3001] loss: 0.0045146  | loss_wrt: 0.00166  | loss_unl: 0.00358  | learning_rate: 0.00041\n",
      "OA: 0.8999  | AA:  0.8394  | Kappa:  0.8861  | Time: 54.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1550,  3101] loss: 0.0068134  | loss_wrt: 0.00428  | loss_unl: 0.00805  | learning_rate: 0.00036\n",
      "OA: 0.8924  | AA:  0.8358  | Kappa:  0.8776  | Time: 54.1\n",
      "[1600,  3201] loss: 0.0065429  | loss_wrt: 0.00181  | loss_unl: 0.00459  | learning_rate: 0.00036\n",
      "OA: 0.8977  | AA:  0.8376  | Kappa:  0.8836  | Time: 53.9\n",
      "[1650,  3301] loss: 0.0030427  | loss_wrt: 0.00101  | loss_unl: 0.00289  | learning_rate: 0.00036\n",
      "OA: 0.8907  | AA:  0.8387  | Kappa:  0.8757  | Time: 54.0\n",
      "[1700,  3401] loss: 0.0024633  | loss_wrt: 0.00075  | loss_unl: 0.00311  | learning_rate: 0.00036\n",
      "OA: 0.9002  | AA:  0.8379  | Kappa:  0.8865  | Time: 54.1\n",
      "[1750,  3501] loss: 0.0259826  | loss_wrt: 0.00326  | loss_unl: 0.00451  | learning_rate: 0.00036\n",
      "OA: 0.8859  | AA:  0.8357  | Kappa:  0.8703  | Time: 53.9\n",
      "[1800,  3601] loss: 0.0051314  | loss_wrt: 0.00179  | loss_unl: 0.00443  | learning_rate: 0.00036\n",
      "OA: 0.8943  | AA:  0.8379  | Kappa:  0.8797  | Time: 53.9\n",
      "[1850,  3701] loss: 0.0119976  | loss_wrt: 0.00455  | loss_unl: 0.00627  | learning_rate: 0.00036\n",
      "OA: 0.8933  | AA:  0.8528  | Kappa:  0.8788  | Time: 54.1\n",
      "[1900,  3801] loss: 0.0327993  | loss_wrt: 0.00265  | loss_unl: 0.00515  | learning_rate: 0.00036\n",
      "OA: 0.8971  | AA:  0.8430  | Kappa:  0.8829  | Time: 53.9\n",
      "[1950,  3901] loss: 0.0029078  | loss_wrt: 0.00139  | loss_unl: 0.00366  | learning_rate: 0.00036\n",
      "OA: 0.8992  | AA:  0.8439  | Kappa:  0.8853  | Time: 54.0\n",
      "[2000,  4001] loss: 0.0266264  | loss_wrt: 0.00192  | loss_unl: 0.00370  | learning_rate: 0.00036\n",
      "OA: 0.8972  | AA:  0.8478  | Kappa:  0.8831  | Time: 54.1\n",
      "Finished Training\n",
      "model saved\n",
      "[0.94871795 0.79571664 0.95460993 0.88059701 0.91240876 0.95483871\n",
      " 0.         0.99261084 0.47058824 0.84261501 0.86344034 0.93650794\n",
      " 1.         0.96837209 0.99695122 0.96202532]\n",
      "0.8977037887485648 0.8424999997539402 0.8836342398828037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([256, 200, 31, 31]) torch.Size([256, 200, 31, 31])\n",
      "=> all bands acc: 0.711\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: -4.48 | loss:0.699 | 100 bands | 7.6s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: -4.27 | loss:0.719 | 100 bands | 4.4s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -4.03 | loss:0.705 | 100 bands | 4.4s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: -3.92 | loss:0.724 | 100 bands | 4.5s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -3.84 | loss:0.719 | 100 bands | 4.4s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: -3.93 | loss:0.704 | 100 bands | 4.5s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: -4.03 | loss:0.725 | 100 bands | 4.6s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: -3.98 | loss:0.701 | 100 bands | 4.5s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: -3.77 | loss:0.711 | 100 bands | 4.5s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: -3.62 | loss:0.695 | 100 bands | 4.5s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: -3.68 | loss:0.702 | 100 bands | 4.6s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: -3.59 | loss:0.690 | 100 bands | 4.5s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: -3.39 | loss:0.707 | 100 bands | 4.6s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: -3.59 | loss:0.696 | 100 bands | 4.7s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: -3.85 | loss:0.686 | 100 bands | 4.7s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: -3.71 | loss:0.685 | 100 bands | 4.6s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: -3.42 | loss:0.696 | 100 bands | 4.5s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: -3.33 | loss:0.696 | 100 bands | 4.6s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: -3.23 | loss:0.690 | 100 bands | 4.6s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: -3.09 | loss:0.684 | 100 bands | 4.6s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: -3.06 | loss:0.675 | 100 bands | 4.7s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: -2.98 | loss:0.679 | 100 bands | 4.6s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: -2.88 | loss:0.689 | 100 bands | 4.5s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: -2.65 | loss:0.677 | 100 bands | 4.5s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: -2.63 | loss:0.690 | 100 bands | 4.6s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: -2.76 | loss:0.667 | 100 bands | 4.7s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: -2.97 | loss:0.673 | 100 bands | 4.8s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: -3.02 | loss:0.664 | 100 bands | 4.8s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: -3.28 | loss:0.657 | 100 bands | 4.9s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: -3.40 | loss:0.668 | 100 bands | 4.9s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: -3.34 | loss:0.669 | 100 bands | 4.8s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: -3.24 | loss:0.687 | 100 bands | 4.8s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: -3.40 | loss:0.658 | 100 bands | 4.8s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: -3.81 | loss:0.683 | 100 bands | 5.1s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: -3.60 | loss:0.689 | 100 bands | 4.8s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: -3.43 | loss:0.663 | 100 bands | 4.8s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: -3.20 | loss:0.661 | 100 bands | 4.8s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: -3.23 | loss:0.681 | 100 bands | 4.9s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: -3.07 | loss:0.653 | 100 bands | 4.9s\n",
      "r_max, 0.6637532938384538\n",
      "Done\n",
      "time :189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-22 14:18:44.231458: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-22 14:18:44.234296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-22 14:18:44.234454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-22 14:18:44.672370: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-22 14:18:44.672466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-22 14:18:44.672515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-22 14:18:44.672711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda:0\n",
      "Start training...\n",
      "[25,   101] loss: 1.2570320  | loss_wrt: 0.14039  | loss_unl: 0.15717  | learning_rate: 0.00100\n",
      "OA: 0.9040  | AA:  0.7305  | Kappa:  0.8906  | Time: 16.3\n",
      "[50,   201] loss: 0.1375447  | loss_wrt: 0.05600  | loss_unl: 0.06935  | learning_rate: 0.00090\n",
      "OA: 0.9631  | AA:  0.8849  | Kappa:  0.9580  | Time: 16.2\n",
      "[75,   301] loss: 0.0547207  | loss_wrt: 0.03409  | loss_unl: 0.03624  | learning_rate: 0.00081\n",
      "OA: 0.9662  | AA:  0.8893  | Kappa:  0.9615  | Time: 16.3\n",
      "[100,   401] loss: 0.0771940  | loss_wrt: 0.05165  | loss_unl: 0.05420  | learning_rate: 0.00073\n",
      "OA: 0.9661  | AA:  0.9044  | Kappa:  0.9614  | Time: 16.3\n",
      "[125,   501] loss: 0.0400935  | loss_wrt: 0.02162  | loss_unl: 0.02838  | learning_rate: 0.00066\n",
      "OA: 0.9724  | AA:  0.8963  | Kappa:  0.9686  | Time: 16.3\n",
      "[150,   601] loss: 0.0233543  | loss_wrt: 0.01432  | loss_unl: 0.02061  | learning_rate: 0.00059\n",
      "OA: 0.9739  | AA:  0.9047  | Kappa:  0.9703  | Time: 16.3\n",
      "[175,   701] loss: 0.0161623  | loss_wrt: 0.01105  | loss_unl: 0.01664  | learning_rate: 0.00053\n",
      "OA: 0.9743  | AA:  0.8928  | Kappa:  0.9707  | Time: 16.3\n",
      "[200,   801] loss: 0.0118360  | loss_wrt: 0.00725  | loss_unl: 0.01149  | learning_rate: 0.00048\n",
      "OA: 0.9763  | AA:  0.8975  | Kappa:  0.9730  | Time: 16.3\n",
      "[225,   901] loss: 0.0091929  | loss_wrt: 0.00593  | loss_unl: 0.00891  | learning_rate: 0.00043\n",
      "OA: 0.9765  | AA:  0.8997  | Kappa:  0.9732  | Time: 16.3\n",
      "[250,  1001] loss: 0.0071733  | loss_wrt: 0.00481  | loss_unl: 0.00781  | learning_rate: 0.00039\n",
      "OA: 0.9769  | AA:  0.9037  | Kappa:  0.9737  | Time: 16.3\n",
      "[275,  1101] loss: 0.0059067  | loss_wrt: 0.00338  | loss_unl: 0.00771  | learning_rate: 0.00035\n",
      "OA: 0.9770  | AA:  0.9047  | Kappa:  0.9738  | Time: 16.3\n",
      "[300,  1201] loss: 0.0047454  | loss_wrt: 0.00331  | loss_unl: 0.00453  | learning_rate: 0.00031\n",
      "OA: 0.9765  | AA:  0.8960  | Kappa:  0.9732  | Time: 16.3\n",
      "[325,  1301] loss: 0.0039062  | loss_wrt: 0.00237  | loss_unl: 0.00406  | learning_rate: 0.00028\n",
      "OA: 0.9759  | AA:  0.8942  | Kappa:  0.9725  | Time: 16.2\n",
      "[350,  1401] loss: 0.0032286  | loss_wrt: 0.00199  | loss_unl: 0.00326  | learning_rate: 0.00025\n",
      "OA: 0.9765  | AA:  0.9026  | Kappa:  0.9732  | Time: 16.3\n",
      "[375,  1501] loss: 0.0027513  | loss_wrt: 0.00174  | loss_unl: 0.00251  | learning_rate: 0.00023\n",
      "OA: 0.9762  | AA:  0.8995  | Kappa:  0.9729  | Time: 16.2\n",
      "[400,  1601] loss: 0.0022661  | loss_wrt: 0.00159  | loss_unl: 0.00222  | learning_rate: 0.00021\n",
      "OA: 0.9760  | AA:  0.8994  | Kappa:  0.9726  | Time: 16.2\n",
      "[425,  1701] loss: 0.0020024  | loss_wrt: 0.00129  | loss_unl: 0.00179  | learning_rate: 0.00019\n",
      "OA: 0.9770  | AA:  0.8999  | Kappa:  0.9738  | Time: 16.2\n",
      "[450,  1801] loss: 0.0017639  | loss_wrt: 0.00129  | loss_unl: 0.00147  | learning_rate: 0.00017\n",
      "OA: 0.9761  | AA:  0.8993  | Kappa:  0.9728  | Time: 16.3\n",
      "[475,  1901] loss: 0.0015855  | loss_wrt: 0.00112  | loss_unl: 0.00149  | learning_rate: 0.00015\n",
      "OA: 0.9749  | AA:  0.9001  | Kappa:  0.9713  | Time: 16.4\n",
      "[500,  2001] loss: 0.0013712  | loss_wrt: 0.00103  | loss_unl: 0.00141  | learning_rate: 0.00014\n",
      "OA: 0.9757  | AA:  0.9037  | Kappa:  0.9722  | Time: 16.3\n",
      "Finished Training\n",
      "(8710, 2)\n",
      "[0.8974359  0.94481054 0.99432624 1.         0.97323601 0.95967742\n",
      " 0.5        0.99753695 0.47058824 0.97820823 0.99233349 0.98611111\n",
      " 1.         0.98046512 1.         0.78481013]\n",
      "0.9756601607347876 0.9037212107432695 0.9722463098964063\n",
      "(21025, 2)\n",
      "10776\n",
      "108\n",
      "Finished!\n",
      "512\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.1917631  | loss_wrt: 0.13544  | loss_unl: 0.16870  | learning_rate: 0.00050\n",
      "OA: 0.7759  | AA:  0.5840  | Kappa:  0.7411  | Time: 55.2\n",
      "[100,   201] loss: 0.2675004  | loss_wrt: 0.09431  | loss_unl: 0.12784  | learning_rate: 0.00050\n",
      "OA: 0.8509  | AA:  0.7198  | Kappa:  0.8293  | Time: 53.4\n",
      "[150,   301] loss: 0.1532357  | loss_wrt: 0.05926  | loss_unl: 0.09010  | learning_rate: 0.00050\n",
      "OA: 0.8499  | AA:  0.7153  | Kappa:  0.8279  | Time: 53.4\n",
      "[200,   401] loss: 0.0865923  | loss_wrt: 0.05065  | loss_unl: 0.07600  | learning_rate: 0.00050\n",
      "OA: 0.8746  | AA:  0.7514  | Kappa:  0.8566  | Time: 53.5\n",
      "[250,   501] loss: 0.0705192  | loss_wrt: 0.03910  | loss_unl: 0.06109  | learning_rate: 0.00050\n",
      "OA: 0.8543  | AA:  0.7277  | Kappa:  0.8334  | Time: 53.4\n",
      "[300,   601] loss: 0.1651233  | loss_wrt: 0.04276  | loss_unl: 0.05967  | learning_rate: 0.00050\n",
      "OA: 0.8575  | AA:  0.7180  | Kappa:  0.8369  | Time: 53.4\n",
      "[350,   701] loss: 0.0985570  | loss_wrt: 0.03900  | loss_unl: 0.05820  | learning_rate: 0.00050\n",
      "OA: 0.8423  | AA:  0.7162  | Kappa:  0.8184  | Time: 53.5\n",
      "[400,   801] loss: 0.0604669  | loss_wrt: 0.02049  | loss_unl: 0.03325  | learning_rate: 0.00050\n",
      "OA: 0.8899  | AA:  0.7664  | Kappa:  0.8741  | Time: 53.4\n",
      "[450,   901] loss: 0.1309372  | loss_wrt: 0.04749  | loss_unl: 0.05293  | learning_rate: 0.00050\n",
      "OA: 0.8652  | AA:  0.7510  | Kappa:  0.8458  | Time: 53.4\n",
      "[500,  1001] loss: 0.0409238  | loss_wrt: 0.01617  | loss_unl: 0.02909  | learning_rate: 0.00050\n",
      "OA: 0.8881  | AA:  0.7640  | Kappa:  0.8719  | Time: 53.5\n",
      "[550,  1101] loss: 0.0819421  | loss_wrt: 0.02689  | loss_unl: 0.03642  | learning_rate: 0.00045\n",
      "OA: 0.8860  | AA:  0.7646  | Kappa:  0.8696  | Time: 53.3\n",
      "[600,  1201] loss: 0.0557498  | loss_wrt: 0.01652  | loss_unl: 0.03059  | learning_rate: 0.00045\n",
      "OA: 0.8960  | AA:  0.7732  | Kappa:  0.8812  | Time: 53.4\n",
      "[650,  1301] loss: 0.0523556  | loss_wrt: 0.01566  | loss_unl: 0.04217  | learning_rate: 0.00045\n",
      "OA: 0.8792  | AA:  0.7628  | Kappa:  0.8616  | Time: 53.5\n",
      "[700,  1401] loss: 0.0537604  | loss_wrt: 0.01231  | loss_unl: 0.02710  | learning_rate: 0.00045\n",
      "OA: 0.8939  | AA:  0.7801  | Kappa:  0.8789  | Time: 53.4\n",
      "[750,  1501] loss: 0.0281897  | loss_wrt: 0.01219  | loss_unl: 0.02116  | learning_rate: 0.00045\n",
      "OA: 0.8955  | AA:  0.7787  | Kappa:  0.8804  | Time: 53.4\n",
      "[800,  1601] loss: 0.1205199  | loss_wrt: 0.01815  | loss_unl: 0.02638  | learning_rate: 0.00045\n",
      "OA: 0.8887  | AA:  0.7785  | Kappa:  0.8729  | Time: 53.5\n",
      "[850,  1701] loss: 0.0489413  | loss_wrt: 0.01902  | loss_unl: 0.03014  | learning_rate: 0.00045\n",
      "OA: 0.8755  | AA:  0.7330  | Kappa:  0.8573  | Time: 53.4\n",
      "[900,  1801] loss: 0.0581075  | loss_wrt: 0.01354  | loss_unl: 0.02165  | learning_rate: 0.00045\n",
      "OA: 0.8944  | AA:  0.7677  | Kappa:  0.8792  | Time: 53.4\n",
      "[950,  1901] loss: 0.0213738  | loss_wrt: 0.00810  | loss_unl: 0.01757  | learning_rate: 0.00045\n",
      "OA: 0.9020  | AA:  0.7793  | Kappa:  0.8880  | Time: 53.5\n",
      "[1000,  2001] loss: 0.0166995  | loss_wrt: 0.00618  | loss_unl: 0.01653  | learning_rate: 0.00045\n",
      "OA: 0.8899  | AA:  0.7659  | Kappa:  0.8739  | Time: 53.4\n",
      "[1050,  2101] loss: 0.0134342  | loss_wrt: 0.00626  | loss_unl: 0.01504  | learning_rate: 0.00041\n",
      "OA: 0.8962  | AA:  0.7711  | Kappa:  0.8816  | Time: 53.4\n",
      "[1100,  2201] loss: 0.0298021  | loss_wrt: 0.00715  | loss_unl: 0.01734  | learning_rate: 0.00041\n",
      "OA: 0.8956  | AA:  0.7792  | Kappa:  0.8807  | Time: 53.5\n",
      "[1150,  2301] loss: 0.0644177  | loss_wrt: 0.00830  | loss_unl: 0.01474  | learning_rate: 0.00041\n",
      "OA: 0.9022  | AA:  0.7791  | Kappa:  0.8883  | Time: 53.4\n",
      "[1200,  2401] loss: 0.0281272  | loss_wrt: 0.00824  | loss_unl: 0.01357  | learning_rate: 0.00041\n",
      "OA: 0.9003  | AA:  0.7729  | Kappa:  0.8862  | Time: 53.4\n",
      "[1250,  2501] loss: 0.0191347  | loss_wrt: 0.00885  | loss_unl: 0.01449  | learning_rate: 0.00041\n",
      "OA: 0.9026  | AA:  0.7733  | Kappa:  0.8888  | Time: 53.5\n",
      "[1300,  2601] loss: 0.0096649  | loss_wrt: 0.00380  | loss_unl: 0.01060  | learning_rate: 0.00041\n",
      "OA: 0.8918  | AA:  0.7617  | Kappa:  0.8766  | Time: 53.4\n",
      "[1350,  2701] loss: 0.0424510  | loss_wrt: 0.00924  | loss_unl: 0.01602  | learning_rate: 0.00041\n",
      "OA: 0.8917  | AA:  0.7765  | Kappa:  0.8766  | Time: 53.4\n",
      "[1400,  2801] loss: 0.0454252  | loss_wrt: 0.00633  | loss_unl: 0.01157  | learning_rate: 0.00041\n",
      "OA: 0.8947  | AA:  0.7738  | Kappa:  0.8798  | Time: 53.5\n",
      "[1450,  2901] loss: 0.0090286  | loss_wrt: 0.00306  | loss_unl: 0.00996  | learning_rate: 0.00041\n",
      "OA: 0.9052  | AA:  0.7875  | Kappa:  0.8918  | Time: 53.4\n",
      "[1500,  3001] loss: 0.0093380  | loss_wrt: 0.00465  | loss_unl: 0.00906  | learning_rate: 0.00041\n",
      "OA: 0.9061  | AA:  0.7842  | Kappa:  0.8928  | Time: 53.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1550,  3101] loss: 0.0244335  | loss_wrt: 0.00559  | loss_unl: 0.01220  | learning_rate: 0.00036\n",
      "OA: 0.8992  | AA:  0.7829  | Kappa:  0.8851  | Time: 53.5\n",
      "[1600,  3201] loss: 0.0078135  | loss_wrt: 0.00252  | loss_unl: 0.00709  | learning_rate: 0.00036\n",
      "OA: 0.9093  | AA:  0.7893  | Kappa:  0.8965  | Time: 53.4\n",
      "[1650,  3301] loss: 0.0096059  | loss_wrt: 0.00342  | loss_unl: 0.00829  | learning_rate: 0.00036\n",
      "OA: 0.9048  | AA:  0.7853  | Kappa:  0.8915  | Time: 53.4\n",
      "[1700,  3401] loss: 0.0089981  | loss_wrt: 0.00253  | loss_unl: 0.00606  | learning_rate: 0.00036\n",
      "OA: 0.9021  | AA:  0.7763  | Kappa:  0.8882  | Time: 53.5\n",
      "[1750,  3501] loss: 0.0054325  | loss_wrt: 0.00246  | loss_unl: 0.00753  | learning_rate: 0.00036\n",
      "OA: 0.9060  | AA:  0.7788  | Kappa:  0.8927  | Time: 53.4\n",
      "[1800,  3601] loss: 0.0083193  | loss_wrt: 0.00293  | loss_unl: 0.00622  | learning_rate: 0.00036\n",
      "OA: 0.9062  | AA:  0.7863  | Kappa:  0.8929  | Time: 53.4\n",
      "[1850,  3701] loss: 0.0042216  | loss_wrt: 0.00157  | loss_unl: 0.00489  | learning_rate: 0.00036\n",
      "OA: 0.9106  | AA:  0.7888  | Kappa:  0.8980  | Time: 53.5\n",
      "[1900,  3801] loss: 0.0033470  | loss_wrt: 0.00130  | loss_unl: 0.00488  | learning_rate: 0.00036\n",
      "OA: 0.9101  | AA:  0.7887  | Kappa:  0.8975  | Time: 53.4\n",
      "[1950,  3901] loss: 0.0028451  | loss_wrt: 0.00156  | loss_unl: 0.00329  | learning_rate: 0.00036\n",
      "OA: 0.9093  | AA:  0.7823  | Kappa:  0.8965  | Time: 53.4\n",
      "[2000,  4001] loss: 0.0071991  | loss_wrt: 0.00284  | loss_unl: 0.00412  | learning_rate: 0.00036\n",
      "OA: 0.9092  | AA:  0.7907  | Kappa:  0.8964  | Time: 53.5\n",
      "Finished Training\n",
      "model saved\n",
      "[0.82051282 0.95963756 0.89219858 0.94527363 0.79318735 0.73225806\n",
      " 0.         1.         0.         0.82687651 0.98418783 0.8531746\n",
      " 0.99425287 0.92093023 0.91768293 0.98734177]\n",
      "0.9082663605051665 0.7892196724472302 0.8953164919594939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([256, 200, 31, 31]) torch.Size([256, 200, 31, 31])\n",
      "=> all bands acc: 0.460\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: -4.70 | loss:0.463 | 100 bands | 7.7s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: -4.45 | loss:0.463 | 100 bands | 4.4s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -4.35 | loss:0.455 | 100 bands | 4.5s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: -4.24 | loss:0.453 | 100 bands | 4.5s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -4.24 | loss:0.456 | 100 bands | 4.4s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: -4.13 | loss:0.456 | 100 bands | 4.4s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: -4.19 | loss:0.456 | 100 bands | 4.4s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: -4.22 | loss:0.462 | 100 bands | 4.5s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: -4.45 | loss:0.456 | 100 bands | 4.5s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: -4.53 | loss:0.459 | 100 bands | 4.5s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: -4.73 | loss:0.456 | 100 bands | 4.6s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: -4.88 | loss:0.458 | 100 bands | 4.6s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: -4.81 | loss:0.457 | 100 bands | 4.6s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: -4.55 | loss:0.454 | 100 bands | 4.5s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: -4.28 | loss:0.460 | 100 bands | 4.4s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: -4.20 | loss:0.454 | 100 bands | 4.5s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: -4.16 | loss:0.455 | 100 bands | 4.5s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: -4.21 | loss:0.454 | 100 bands | 4.5s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: -4.09 | loss:0.458 | 100 bands | 4.5s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: -4.30 | loss:0.450 | 100 bands | 4.6s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: -4.71 | loss:0.454 | 100 bands | 4.7s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: -4.56 | loss:0.453 | 100 bands | 4.5s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: -4.46 | loss:0.455 | 100 bands | 4.5s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: -4.44 | loss:0.455 | 100 bands | 4.5s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: -4.52 | loss:0.459 | 100 bands | 4.6s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: -4.28 | loss:0.451 | 100 bands | 4.5s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: -4.16 | loss:0.453 | 100 bands | 4.5s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: -4.22 | loss:0.458 | 100 bands | 4.5s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: -4.24 | loss:0.451 | 100 bands | 4.5s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: -4.14 | loss:0.453 | 100 bands | 4.5s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: -4.10 | loss:0.453 | 100 bands | 4.5s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: -4.06 | loss:0.455 | 100 bands | 4.5s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: -3.98 | loss:0.453 | 100 bands | 4.5s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: -3.96 | loss:0.456 | 100 bands | 4.5s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: -3.98 | loss:0.456 | 100 bands | 4.5s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: -3.95 | loss:0.455 | 100 bands | 4.5s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: -3.90 | loss:0.457 | 100 bands | 4.5s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: -3.93 | loss:0.448 | 100 bands | 4.5s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: -3.99 | loss:0.451 | 100 bands | 4.5s\n",
      "r_max, 0.45428441115655005\n",
      "Done\n",
      "time :183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-22 15:03:17.387670: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-22 15:03:17.390544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-22 15:03:17.390703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-22 15:03:17.828616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-22 15:03:17.828717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-22 15:03:17.828766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-22 15:03:17.828967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda:0\n",
      "Start training...\n",
      "[25,   101] loss: 1.4864410  | loss_wrt: 0.15359  | loss_unl: 0.16904  | learning_rate: 0.00100\n",
      "OA: 0.8374  | AA:  0.6505  | Kappa:  0.8142  | Time: 16.3\n",
      "[50,   201] loss: 0.1760864  | loss_wrt: 0.06211  | loss_unl: 0.09196  | learning_rate: 0.00090\n",
      "OA: 0.9416  | AA:  0.9177  | Kappa:  0.9333  | Time: 16.2\n",
      "[75,   301] loss: 0.0759699  | loss_wrt: 0.03715  | loss_unl: 0.04585  | learning_rate: 0.00081\n",
      "OA: 0.9491  | AA:  0.9240  | Kappa:  0.9419  | Time: 16.3\n",
      "[100,   401] loss: 0.0375249  | loss_wrt: 0.02066  | loss_unl: 0.03030  | learning_rate: 0.00073\n",
      "OA: 0.9548  | AA:  0.9224  | Kappa:  0.9484  | Time: 16.3\n",
      "[125,   501] loss: 0.0235572  | loss_wrt: 0.01350  | loss_unl: 0.02100  | learning_rate: 0.00066\n",
      "OA: 0.9569  | AA:  0.9120  | Kappa:  0.9508  | Time: 16.3\n",
      "[150,   601] loss: 0.0166968  | loss_wrt: 0.00955  | loss_unl: 0.01676  | learning_rate: 0.00059\n",
      "OA: 0.9574  | AA:  0.9102  | Kappa:  0.9514  | Time: 16.3\n",
      "[175,   701] loss: 0.0122977  | loss_wrt: 0.00825  | loss_unl: 0.01323  | learning_rate: 0.00053\n",
      "OA: 0.9569  | AA:  0.9123  | Kappa:  0.9508  | Time: 16.3\n",
      "[200,   801] loss: 0.0095392  | loss_wrt: 0.00688  | loss_unl: 0.01053  | learning_rate: 0.00048\n",
      "OA: 0.9544  | AA:  0.9170  | Kappa:  0.9480  | Time: 16.3\n",
      "[225,   901] loss: 0.0072909  | loss_wrt: 0.00570  | loss_unl: 0.00762  | learning_rate: 0.00043\n",
      "OA: 0.9541  | AA:  0.9100  | Kappa:  0.9475  | Time: 16.3\n",
      "[250,  1001] loss: 0.0058843  | loss_wrt: 0.00380  | loss_unl: 0.00656  | learning_rate: 0.00039\n",
      "OA: 0.9541  | AA:  0.9075  | Kappa:  0.9476  | Time: 16.3\n",
      "[275,  1101] loss: 0.0050476  | loss_wrt: 0.00335  | loss_unl: 0.00447  | learning_rate: 0.00035\n",
      "OA: 0.9543  | AA:  0.9079  | Kappa:  0.9478  | Time: 16.2\n",
      "[300,  1201] loss: 0.0039040  | loss_wrt: 0.00355  | loss_unl: 0.00432  | learning_rate: 0.00031\n",
      "OA: 0.9546  | AA:  0.9190  | Kappa:  0.9482  | Time: 16.3\n",
      "[325,  1301] loss: 0.0033180  | loss_wrt: 0.00226  | loss_unl: 0.00284  | learning_rate: 0.00028\n",
      "OA: 0.9543  | AA:  0.9112  | Kappa:  0.9478  | Time: 16.3\n",
      "[350,  1401] loss: 0.0027722  | loss_wrt: 0.00205  | loss_unl: 0.00306  | learning_rate: 0.00025\n",
      "OA: 0.9526  | AA:  0.9090  | Kappa:  0.9459  | Time: 16.3\n",
      "[375,  1501] loss: 0.0023601  | loss_wrt: 0.00200  | loss_unl: 0.00220  | learning_rate: 0.00023\n",
      "OA: 0.9540  | AA:  0.9125  | Kappa:  0.9474  | Time: 16.3\n",
      "[400,  1601] loss: 0.0020622  | loss_wrt: 0.00135  | loss_unl: 0.00179  | learning_rate: 0.00021\n",
      "OA: 0.9529  | AA:  0.9119  | Kappa:  0.9463  | Time: 16.2\n",
      "[425,  1701] loss: 0.0018265  | loss_wrt: 0.00136  | loss_unl: 0.00144  | learning_rate: 0.00019\n",
      "OA: 0.9528  | AA:  0.9114  | Kappa:  0.9461  | Time: 16.2\n",
      "[450,  1801] loss: 0.0015914  | loss_wrt: 0.00123  | loss_unl: 0.00146  | learning_rate: 0.00017\n",
      "OA: 0.9528  | AA:  0.9105  | Kappa:  0.9461  | Time: 16.3\n",
      "[475,  1901] loss: 0.0014172  | loss_wrt: 0.00101  | loss_unl: 0.00168  | learning_rate: 0.00015\n",
      "OA: 0.9526  | AA:  0.9016  | Kappa:  0.9459  | Time: 16.2\n",
      "[500,  2001] loss: 0.0012295  | loss_wrt: 0.00097  | loss_unl: 0.00162  | learning_rate: 0.00014\n",
      "OA: 0.9533  | AA:  0.9113  | Kappa:  0.9466  | Time: 16.3\n",
      "Finished Training\n",
      "(8710, 2)\n",
      "[0.74358974 0.94069193 0.96170213 0.88557214 0.88077859 0.99032258\n",
      " 1.         1.         0.58823529 0.83656174 0.98466699 0.95039683\n",
      " 0.99425287 1.         0.97560976 0.84810127]\n",
      "0.9532721010332951 0.9112801157476251 0.9466490504203097\n",
      "(21025, 2)\n",
      "10776\n",
      "108\n",
      "Finished!\n",
      "512\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.2853792  | loss_wrt: 0.17193  | loss_unl: 0.20553  | learning_rate: 0.00050\n",
      "OA: 0.7904  | AA:  0.6486  | Kappa:  0.7599  | Time: 55.4\n",
      "[100,   201] loss: 0.1924490  | loss_wrt: 0.07347  | loss_unl: 0.10895  | learning_rate: 0.00050\n",
      "OA: 0.8390  | AA:  0.7291  | Kappa:  0.8158  | Time: 53.7\n",
      "[150,   301] loss: 0.1456209  | loss_wrt: 0.06913  | loss_unl: 0.09194  | learning_rate: 0.00050\n",
      "OA: 0.8455  | AA:  0.7368  | Kappa:  0.8235  | Time: 53.6\n",
      "[200,   401] loss: 0.1377339  | loss_wrt: 0.06725  | loss_unl: 0.08704  | learning_rate: 0.00050\n",
      "OA: 0.8276  | AA:  0.7673  | Kappa:  0.8037  | Time: 53.7\n",
      "[250,   501] loss: 0.1164521  | loss_wrt: 0.03445  | loss_unl: 0.06862  | learning_rate: 0.00050\n",
      "OA: 0.8680  | AA:  0.7732  | Kappa:  0.8492  | Time: 53.6\n",
      "[300,   601] loss: 0.0619776  | loss_wrt: 0.03452  | loss_unl: 0.05868  | learning_rate: 0.00050\n",
      "OA: 0.8520  | AA:  0.7682  | Kappa:  0.8310  | Time: 53.6\n",
      "[350,   701] loss: 0.0681299  | loss_wrt: 0.02624  | loss_unl: 0.05499  | learning_rate: 0.00050\n",
      "OA: 0.8753  | AA:  0.7940  | Kappa:  0.8574  | Time: 53.7\n",
      "[400,   801] loss: 0.0458639  | loss_wrt: 0.03072  | loss_unl: 0.04785  | learning_rate: 0.00050\n",
      "OA: 0.8496  | AA:  0.8031  | Kappa:  0.8288  | Time: 53.6\n",
      "[450,   901] loss: 0.0681555  | loss_wrt: 0.02108  | loss_unl: 0.03377  | learning_rate: 0.00050\n",
      "OA: 0.8534  | AA:  0.7597  | Kappa:  0.8325  | Time: 53.6\n",
      "[500,  1001] loss: 0.1575837  | loss_wrt: 0.02625  | loss_unl: 0.03832  | learning_rate: 0.00050\n",
      "OA: 0.8629  | AA:  0.7689  | Kappa:  0.8429  | Time: 53.7\n",
      "[550,  1101] loss: 0.1068339  | loss_wrt: 0.02526  | loss_unl: 0.03511  | learning_rate: 0.00045\n",
      "OA: 0.8592  | AA:  0.7852  | Kappa:  0.8388  | Time: 53.6\n",
      "[600,  1201] loss: 0.0293533  | loss_wrt: 0.01325  | loss_unl: 0.02747  | learning_rate: 0.00045\n",
      "OA: 0.8759  | AA:  0.8006  | Kappa:  0.8583  | Time: 53.7\n",
      "[650,  1301] loss: 0.0480678  | loss_wrt: 0.01645  | loss_unl: 0.03161  | learning_rate: 0.00045\n",
      "OA: 0.8834  | AA:  0.7939  | Kappa:  0.8668  | Time: 53.8\n",
      "[700,  1401] loss: 0.0650332  | loss_wrt: 0.02458  | loss_unl: 0.02846  | learning_rate: 0.00045\n",
      "OA: 0.8848  | AA:  0.8174  | Kappa:  0.8682  | Time: 53.7\n",
      "[750,  1501] loss: 0.0184030  | loss_wrt: 0.00943  | loss_unl: 0.02032  | learning_rate: 0.00045\n",
      "OA: 0.8607  | AA:  0.7871  | Kappa:  0.8410  | Time: 53.6\n",
      "[800,  1601] loss: 0.0517670  | loss_wrt: 0.01462  | loss_unl: 0.02474  | learning_rate: 0.00045\n",
      "OA: 0.8754  | AA:  0.8101  | Kappa:  0.8578  | Time: 53.7\n",
      "[850,  1701] loss: 0.0381887  | loss_wrt: 0.01327  | loss_unl: 0.02399  | learning_rate: 0.00045\n",
      "OA: 0.8620  | AA:  0.8133  | Kappa:  0.8426  | Time: 53.6\n",
      "[900,  1801] loss: 0.0347055  | loss_wrt: 0.00697  | loss_unl: 0.01624  | learning_rate: 0.00045\n",
      "OA: 0.8869  | AA:  0.8095  | Kappa:  0.8706  | Time: 53.6\n",
      "[950,  1901] loss: 0.0342197  | loss_wrt: 0.00991  | loss_unl: 0.01757  | learning_rate: 0.00045\n",
      "OA: 0.8610  | AA:  0.7698  | Kappa:  0.8406  | Time: 53.8\n",
      "[1000,  2001] loss: 0.0209305  | loss_wrt: 0.00800  | loss_unl: 0.01700  | learning_rate: 0.00045\n",
      "OA: 0.8875  | AA:  0.7991  | Kappa:  0.8714  | Time: 53.6\n",
      "[1050,  2101] loss: 0.0377537  | loss_wrt: 0.00847  | loss_unl: 0.01569  | learning_rate: 0.00041\n",
      "OA: 0.8615  | AA:  0.8025  | Kappa:  0.8416  | Time: 53.6\n",
      "[1100,  2201] loss: 0.0256303  | loss_wrt: 0.00533  | loss_unl: 0.01364  | learning_rate: 0.00041\n",
      "OA: 0.8828  | AA:  0.8091  | Kappa:  0.8659  | Time: 53.8\n",
      "[1150,  2301] loss: 0.0269203  | loss_wrt: 0.00942  | loss_unl: 0.01543  | learning_rate: 0.00041\n",
      "OA: 0.8693  | AA:  0.8069  | Kappa:  0.8507  | Time: 53.6\n",
      "[1200,  2401] loss: 0.0175685  | loss_wrt: 0.00453  | loss_unl: 0.01188  | learning_rate: 0.00041\n",
      "OA: 0.8890  | AA:  0.8137  | Kappa:  0.8730  | Time: 53.6\n",
      "[1250,  2501] loss: 0.0527843  | loss_wrt: 0.00712  | loss_unl: 0.01196  | learning_rate: 0.00041\n",
      "OA: 0.8808  | AA:  0.8125  | Kappa:  0.8637  | Time: 53.7\n",
      "[1300,  2601] loss: 0.0266448  | loss_wrt: 0.00569  | loss_unl: 0.01077  | learning_rate: 0.00041\n",
      "OA: 0.8797  | AA:  0.7962  | Kappa:  0.8623  | Time: 53.6\n",
      "[1350,  2701] loss: 0.0086234  | loss_wrt: 0.00514  | loss_unl: 0.01021  | learning_rate: 0.00041\n",
      "OA: 0.8923  | AA:  0.8187  | Kappa:  0.8769  | Time: 53.6\n",
      "[1400,  2801] loss: 0.0060626  | loss_wrt: 0.00216  | loss_unl: 0.00704  | learning_rate: 0.00041\n",
      "OA: 0.8906  | AA:  0.8142  | Kappa:  0.8749  | Time: 53.7\n",
      "[1450,  2901] loss: 0.0069281  | loss_wrt: 0.00508  | loss_unl: 0.00847  | learning_rate: 0.00041\n",
      "OA: 0.8916  | AA:  0.8159  | Kappa:  0.8761  | Time: 53.6\n",
      "[1500,  3001] loss: 0.0094257  | loss_wrt: 0.00488  | loss_unl: 0.00739  | learning_rate: 0.00041\n",
      "OA: 0.8945  | AA:  0.8215  | Kappa:  0.8793  | Time: 53.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1550,  3101] loss: 0.0085190  | loss_wrt: 0.00568  | loss_unl: 0.01088  | learning_rate: 0.00036\n",
      "OA: 0.8939  | AA:  0.8374  | Kappa:  0.8787  | Time: 53.7\n",
      "[1600,  3201] loss: 0.0048606  | loss_wrt: 0.00157  | loss_unl: 0.00507  | learning_rate: 0.00036\n",
      "OA: 0.8990  | AA:  0.8318  | Kappa:  0.8845  | Time: 53.6\n",
      "[1650,  3301] loss: 0.0163893  | loss_wrt: 0.00522  | loss_unl: 0.01076  | learning_rate: 0.00036\n",
      "OA: 0.8886  | AA:  0.8139  | Kappa:  0.8727  | Time: 53.6\n",
      "[1700,  3401] loss: 0.0213414  | loss_wrt: 0.00456  | loss_unl: 0.01972  | learning_rate: 0.00036\n",
      "OA: 0.8861  | AA:  0.8162  | Kappa:  0.8697  | Time: 53.7\n",
      "[1750,  3501] loss: 0.0053960  | loss_wrt: 0.00174  | loss_unl: 0.00567  | learning_rate: 0.00036\n",
      "OA: 0.8976  | AA:  0.8377  | Kappa:  0.8829  | Time: 53.6\n",
      "[1800,  3601] loss: 0.0149034  | loss_wrt: 0.00469  | loss_unl: 0.00742  | learning_rate: 0.00036\n",
      "OA: 0.8842  | AA:  0.8246  | Kappa:  0.8674  | Time: 53.6\n",
      "[1850,  3701] loss: 0.0056343  | loss_wrt: 0.00206  | loss_unl: 0.00525  | learning_rate: 0.00036\n",
      "OA: 0.8980  | AA:  0.8261  | Kappa:  0.8834  | Time: 53.7\n",
      "[1900,  3801] loss: 0.0139945  | loss_wrt: 0.00258  | loss_unl: 0.00525  | learning_rate: 0.00036\n",
      "OA: 0.8904  | AA:  0.8027  | Kappa:  0.8746  | Time: 53.7\n",
      "[1950,  3901] loss: 0.0063273  | loss_wrt: 0.00377  | loss_unl: 0.00676  | learning_rate: 0.00036\n",
      "OA: 0.8875  | AA:  0.8171  | Kappa:  0.8714  | Time: 53.6\n",
      "[2000,  4001] loss: 0.0133240  | loss_wrt: 0.00305  | loss_unl: 0.00643  | learning_rate: 0.00036\n",
      "OA: 0.8853  | AA:  0.8221  | Kappa:  0.8690  | Time: 53.8\n",
      "Finished Training\n",
      "model saved\n",
      "[0.8974359  0.86985173 0.87375887 0.8358209  0.85158151 0.89032258\n",
      " 0.625      1.         0.41176471 0.81355932 0.97077144 0.88888889\n",
      " 0.99425287 0.88930233 0.82012195 0.72151899]\n",
      "0.896211251435132 0.8346219983724329 0.8813913603373869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([256, 200, 31, 31]) torch.Size([256, 200, 31, 31])\n",
      "=> all bands acc: 0.504\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: -5.43 | loss:0.499 | 100 bands | 7.7s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: -4.77 | loss:0.494 | 100 bands | 4.4s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -4.47 | loss:0.503 | 100 bands | 4.4s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: -4.43 | loss:0.507 | 100 bands | 4.5s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -4.21 | loss:0.500 | 100 bands | 4.4s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: -4.20 | loss:0.505 | 100 bands | 4.5s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: -4.41 | loss:0.483 | 100 bands | 4.6s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: -4.32 | loss:0.497 | 100 bands | 4.5s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: -4.27 | loss:0.486 | 100 bands | 4.6s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: -4.15 | loss:0.498 | 100 bands | 4.5s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: -4.14 | loss:0.483 | 100 bands | 4.6s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: -4.19 | loss:0.486 | 100 bands | 4.6s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: -4.18 | loss:0.475 | 100 bands | 4.6s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: -4.28 | loss:0.491 | 100 bands | 4.7s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: -4.91 | loss:0.481 | 100 bands | 4.9s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: -4.78 | loss:0.486 | 100 bands | 4.7s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: -4.28 | loss:0.487 | 100 bands | 4.5s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: -3.91 | loss:0.500 | 100 bands | 4.5s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: -3.85 | loss:0.479 | 100 bands | 4.6s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: -3.77 | loss:0.493 | 100 bands | 4.6s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: -3.96 | loss:0.486 | 100 bands | 4.7s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: -3.86 | loss:0.485 | 100 bands | 4.6s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: -3.88 | loss:0.494 | 100 bands | 4.6s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: -3.71 | loss:0.486 | 100 bands | 4.5s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: -3.50 | loss:0.488 | 100 bands | 4.5s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: -3.46 | loss:0.489 | 100 bands | 4.6s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: -3.74 | loss:0.480 | 100 bands | 4.7s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: -3.68 | loss:0.478 | 100 bands | 4.6s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: -3.57 | loss:0.477 | 100 bands | 4.6s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: -3.53 | loss:0.482 | 100 bands | 4.6s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: -3.38 | loss:0.478 | 100 bands | 4.6s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: -3.45 | loss:0.486 | 100 bands | 4.6s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: -3.34 | loss:0.488 | 100 bands | 4.6s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: -3.31 | loss:0.480 | 100 bands | 4.6s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: -3.35 | loss:0.493 | 100 bands | 4.6s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: -3.39 | loss:0.478 | 100 bands | 4.6s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: -3.18 | loss:0.487 | 100 bands | 4.5s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: -3.15 | loss:0.484 | 100 bands | 4.5s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: -3.12 | loss:0.489 | 100 bands | 4.6s\n",
      "r_max, 0.478000927138055\n",
      "Done\n",
      "time :186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-22 15:47:53.718484: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-22 15:47:53.721242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-22 15:47:53.721411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-22 15:47:54.157680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-22 15:47:54.157782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-22 15:47:54.157830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-22 15:47:54.158025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda:0\n",
      "Start training...\n",
      "[25,   101] loss: 1.2776748  | loss_wrt: 0.12684  | loss_unl: 0.13855  | learning_rate: 0.00100\n",
      "OA: 0.8901  | AA:  0.6997  | Kappa:  0.8748  | Time: 16.3\n",
      "[50,   201] loss: 0.1355112  | loss_wrt: 0.05757  | loss_unl: 0.06442  | learning_rate: 0.00090\n",
      "OA: 0.9336  | AA:  0.8445  | Kappa:  0.9243  | Time: 16.2\n",
      "[75,   301] loss: 0.0564804  | loss_wrt: 0.02897  | loss_unl: 0.04288  | learning_rate: 0.00081\n",
      "OA: 0.9433  | AA:  0.8905  | Kappa:  0.9354  | Time: 16.2\n",
      "[100,   401] loss: 0.0366606  | loss_wrt: 0.02531  | loss_unl: 0.02809  | learning_rate: 0.00073\n",
      "OA: 0.9524  | AA:  0.8708  | Kappa:  0.9457  | Time: 16.2\n",
      "[125,   501] loss: 0.0226583  | loss_wrt: 0.01355  | loss_unl: 0.01875  | learning_rate: 0.00066\n",
      "OA: 0.9538  | AA:  0.8749  | Kappa:  0.9473  | Time: 16.2\n",
      "[150,   601] loss: 0.0208054  | loss_wrt: 0.03490  | loss_unl: 0.03567  | learning_rate: 0.00059\n",
      "OA: 0.8503  | AA:  0.7759  | Kappa:  0.8299  | Time: 16.2\n",
      "[175,   701] loss: 0.0810117  | loss_wrt: 0.02780  | loss_unl: 0.02724  | learning_rate: 0.00053\n",
      "OA: 0.9561  | AA:  0.8710  | Kappa:  0.9500  | Time: 16.3\n",
      "[200,   801] loss: 0.0243573  | loss_wrt: 0.01369  | loss_unl: 0.02174  | learning_rate: 0.00048\n",
      "OA: 0.9588  | AA:  0.8815  | Kappa:  0.9530  | Time: 16.3\n",
      "[225,   901] loss: 0.0163429  | loss_wrt: 0.00988  | loss_unl: 0.01602  | learning_rate: 0.00043\n",
      "OA: 0.9598  | AA:  0.8903  | Kappa:  0.9542  | Time: 16.2\n",
      "[250,  1001] loss: 0.0121407  | loss_wrt: 0.00768  | loss_unl: 0.01261  | learning_rate: 0.00039\n",
      "OA: 0.9608  | AA:  0.8837  | Kappa:  0.9553  | Time: 16.2\n",
      "[275,  1101] loss: 0.0097751  | loss_wrt: 0.00600  | loss_unl: 0.00932  | learning_rate: 0.00035\n",
      "OA: 0.9615  | AA:  0.8864  | Kappa:  0.9561  | Time: 16.2\n",
      "[300,  1201] loss: 0.0077660  | loss_wrt: 0.00486  | loss_unl: 0.00655  | learning_rate: 0.00031\n",
      "OA: 0.9583  | AA:  0.8814  | Kappa:  0.9524  | Time: 16.3\n",
      "[325,  1301] loss: 0.0064340  | loss_wrt: 0.00454  | loss_unl: 0.00698  | learning_rate: 0.00028\n",
      "OA: 0.9621  | AA:  0.8938  | Kappa:  0.9568  | Time: 16.2\n",
      "[350,  1401] loss: 0.0054213  | loss_wrt: 0.00394  | loss_unl: 0.00538  | learning_rate: 0.00025\n",
      "OA: 0.9606  | AA:  0.8877  | Kappa:  0.9551  | Time: 16.3\n",
      "[375,  1501] loss: 0.0046990  | loss_wrt: 0.00340  | loss_unl: 0.00514  | learning_rate: 0.00023\n",
      "OA: 0.9606  | AA:  0.8917  | Kappa:  0.9551  | Time: 16.3\n",
      "[400,  1601] loss: 0.0038520  | loss_wrt: 0.00291  | loss_unl: 0.00406  | learning_rate: 0.00021\n",
      "OA: 0.9603  | AA:  0.8815  | Kappa:  0.9547  | Time: 16.2\n",
      "[425,  1701] loss: 0.0032216  | loss_wrt: 0.00243  | loss_unl: 0.00362  | learning_rate: 0.00019\n",
      "OA: 0.9597  | AA:  0.8863  | Kappa:  0.9540  | Time: 16.3\n",
      "[450,  1801] loss: 0.0028760  | loss_wrt: 0.00223  | loss_unl: 0.00232  | learning_rate: 0.00017\n",
      "OA: 0.9596  | AA:  0.8864  | Kappa:  0.9539  | Time: 16.2\n",
      "[475,  1901] loss: 0.0025496  | loss_wrt: 0.00164  | loss_unl: 0.00195  | learning_rate: 0.00015\n",
      "OA: 0.9592  | AA:  0.8852  | Kappa:  0.9535  | Time: 16.3\n",
      "[500,  2001] loss: 0.0023067  | loss_wrt: 0.00227  | loss_unl: 0.00234  | learning_rate: 0.00014\n",
      "OA: 0.9594  | AA:  0.8856  | Kappa:  0.9536  | Time: 16.3\n",
      "Finished Training\n",
      "(8710, 2)\n",
      "[0.94871795 0.98682043 0.97021277 0.94527363 0.84671533 0.96612903\n",
      " 0.41666667 1.         0.47058824 0.92009685 0.98370867 0.87103175\n",
      " 0.98850575 0.98139535 1.         0.87341772]\n",
      "0.9593570608495982 0.8855800078805549 0.9536150620002557\n",
      "(21025, 2)\n",
      "10776\n",
      "108\n",
      "Finished!\n",
      "512\n",
      "cuda:0\n",
      "Start training...\n",
      "[50,   101] loss: 1.3541974  | loss_wrt: 0.17189  | loss_unl: 0.20531  | learning_rate: 0.00050\n",
      "OA: 0.7945  | AA:  0.6775  | Kappa:  0.7634  | Time: 55.4\n",
      "[100,   201] loss: 0.3659129  | loss_wrt: 0.10558  | loss_unl: 0.13984  | learning_rate: 0.00050\n",
      "OA: 0.8662  | AA:  0.7962  | Kappa:  0.8469  | Time: 53.5\n",
      "[150,   301] loss: 0.1500101  | loss_wrt: 0.07727  | loss_unl: 0.08742  | learning_rate: 0.00050\n",
      "OA: 0.8832  | AA:  0.8533  | Kappa:  0.8667  | Time: 53.5\n",
      "[200,   401] loss: 0.1017924  | loss_wrt: 0.06175  | loss_unl: 0.08416  | learning_rate: 0.00050\n",
      "OA: 0.8883  | AA:  0.8649  | Kappa:  0.8726  | Time: 53.7\n",
      "[250,   501] loss: 0.0960220  | loss_wrt: 0.03547  | loss_unl: 0.05832  | learning_rate: 0.00050\n",
      "OA: 0.9003  | AA:  0.8854  | Kappa:  0.8863  | Time: 53.5\n",
      "[300,   601] loss: 0.0781412  | loss_wrt: 0.04012  | loss_unl: 0.05607  | learning_rate: 0.00050\n",
      "OA: 0.9160  | AA:  0.8960  | Kappa:  0.9042  | Time: 53.5\n",
      "[350,   701] loss: 0.0527326  | loss_wrt: 0.03670  | loss_unl: 0.05039  | learning_rate: 0.00050\n",
      "OA: 0.8815  | AA:  0.8715  | Kappa:  0.8647  | Time: 53.7\n",
      "[400,   801] loss: 0.0373839  | loss_wrt: 0.01217  | loss_unl: 0.02763  | learning_rate: 0.00050\n",
      "OA: 0.9055  | AA:  0.8951  | Kappa:  0.8924  | Time: 53.5\n",
      "[450,   901] loss: 0.0194215  | loss_wrt: 0.00741  | loss_unl: 0.02271  | learning_rate: 0.00050\n",
      "OA: 0.9204  | AA:  0.9029  | Kappa:  0.9094  | Time: 53.5\n",
      "[500,  1001] loss: 0.0902882  | loss_wrt: 0.02216  | loss_unl: 0.03610  | learning_rate: 0.00050\n",
      "OA: 0.9086  | AA:  0.8883  | Kappa:  0.8957  | Time: 53.7\n",
      "[550,  1101] loss: 0.0315833  | loss_wrt: 0.01293  | loss_unl: 0.02789  | learning_rate: 0.00045\n",
      "OA: 0.9162  | AA:  0.9045  | Kappa:  0.9045  | Time: 53.6\n",
      "[600,  1201] loss: 0.0377559  | loss_wrt: 0.01227  | loss_unl: 0.02044  | learning_rate: 0.00045\n",
      "OA: 0.9209  | AA:  0.9115  | Kappa:  0.9099  | Time: 53.6\n",
      "[650,  1301] loss: 0.0576896  | loss_wrt: 0.01624  | loss_unl: 0.02894  | learning_rate: 0.00045\n",
      "OA: 0.9085  | AA:  0.8925  | Kappa:  0.8958  | Time: 53.7\n",
      "[700,  1401] loss: 0.0628503  | loss_wrt: 0.01385  | loss_unl: 0.02246  | learning_rate: 0.00045\n",
      "OA: 0.9153  | AA:  0.8909  | Kappa:  0.9033  | Time: 53.6\n",
      "[750,  1501] loss: 0.0240247  | loss_wrt: 0.03402  | loss_unl: 0.02033  | learning_rate: 0.00045\n",
      "OA: 0.9224  | AA:  0.9115  | Kappa:  0.9117  | Time: 53.5\n",
      "[800,  1601] loss: 0.0599994  | loss_wrt: 0.01439  | loss_unl: 0.02202  | learning_rate: 0.00045\n",
      "OA: 0.9127  | AA:  0.9052  | Kappa:  0.9007  | Time: 53.7\n",
      "[850,  1701] loss: 0.0767349  | loss_wrt: 0.01242  | loss_unl: 0.01927  | learning_rate: 0.00045\n",
      "OA: 0.9165  | AA:  0.9045  | Kappa:  0.9049  | Time: 53.5\n",
      "[900,  1801] loss: 0.0442299  | loss_wrt: 0.00901  | loss_unl: 0.01631  | learning_rate: 0.00045\n",
      "OA: 0.9186  | AA:  0.9152  | Kappa:  0.9074  | Time: 53.6\n",
      "[950,  1901] loss: 0.0828713  | loss_wrt: 0.01512  | loss_unl: 0.02504  | learning_rate: 0.00045\n",
      "OA: 0.9080  | AA:  0.8907  | Kappa:  0.8952  | Time: 53.7\n",
      "[1000,  2001] loss: 0.0166090  | loss_wrt: 0.00804  | loss_unl: 0.01552  | learning_rate: 0.00045\n",
      "OA: 0.9263  | AA:  0.9205  | Kappa:  0.9162  | Time: 53.6\n",
      "[1050,  2101] loss: 0.0258019  | loss_wrt: 0.01403  | loss_unl: 0.01831  | learning_rate: 0.00041\n",
      "OA: 0.9219  | AA:  0.9184  | Kappa:  0.9110  | Time: 53.5\n",
      "[1100,  2201] loss: 0.0199626  | loss_wrt: 0.00981  | loss_unl: 0.01841  | learning_rate: 0.00041\n",
      "OA: 0.9064  | AA:  0.8924  | Kappa:  0.8932  | Time: 53.7\n",
      "[1150,  2301] loss: 0.0532269  | loss_wrt: 0.00892  | loss_unl: 0.01287  | learning_rate: 0.00041\n",
      "OA: 0.9264  | AA:  0.9157  | Kappa:  0.9162  | Time: 53.6\n",
      "[1200,  2401] loss: 0.0102552  | loss_wrt: 0.00363  | loss_unl: 0.01283  | learning_rate: 0.00041\n",
      "OA: 0.9278  | AA:  0.9221  | Kappa:  0.9179  | Time: 53.6\n",
      "[1250,  2501] loss: 0.0101146  | loss_wrt: 0.00359  | loss_unl: 0.00843  | learning_rate: 0.00041\n",
      "OA: 0.9272  | AA:  0.9201  | Kappa:  0.9172  | Time: 53.7\n",
      "[1300,  2601] loss: 0.0114859  | loss_wrt: 0.00735  | loss_unl: 0.01370  | learning_rate: 0.00041\n",
      "OA: 0.9216  | AA:  0.9186  | Kappa:  0.9108  | Time: 53.6\n",
      "[1350,  2701] loss: 0.0273970  | loss_wrt: 0.00991  | loss_unl: 0.01457  | learning_rate: 0.00041\n",
      "OA: 0.9175  | AA:  0.9098  | Kappa:  0.9061  | Time: 53.6\n",
      "[1400,  2801] loss: 0.0331125  | loss_wrt: 0.01018  | loss_unl: 0.01791  | learning_rate: 0.00041\n",
      "OA: 0.9157  | AA:  0.9009  | Kappa:  0.9042  | Time: 53.6\n",
      "[1450,  2901] loss: 0.0111460  | loss_wrt: 0.00538  | loss_unl: 0.00982  | learning_rate: 0.00041\n",
      "OA: 0.9247  | AA:  0.9177  | Kappa:  0.9143  | Time: 53.5\n",
      "[1500,  3001] loss: 0.0148780  | loss_wrt: 0.00580  | loss_unl: 0.01092  | learning_rate: 0.00041\n",
      "OA: 0.9268  | AA:  0.9106  | Kappa:  0.9166  | Time: 53.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1550,  3101] loss: 0.0107689  | loss_wrt: 0.00313  | loss_unl: 0.00687  | learning_rate: 0.00036\n",
      "OA: 0.9258  | AA:  0.9126  | Kappa:  0.9156  | Time: 53.5\n",
      "[1600,  3201] loss: 0.0073513  | loss_wrt: 0.00360  | loss_unl: 0.00748  | learning_rate: 0.00036\n",
      "OA: 0.9256  | AA:  0.9214  | Kappa:  0.9153  | Time: 53.4\n",
      "[1650,  3301] loss: 0.0394516  | loss_wrt: 0.00484  | loss_unl: 0.00953  | learning_rate: 0.00036\n",
      "OA: 0.9094  | AA:  0.9071  | Kappa:  0.8969  | Time: 53.4\n",
      "[1700,  3401] loss: 0.0112667  | loss_wrt: 0.00419  | loss_unl: 0.00680  | learning_rate: 0.00036\n",
      "OA: 0.9247  | AA:  0.9163  | Kappa:  0.9144  | Time: 53.6\n",
      "[1750,  3501] loss: 0.0069565  | loss_wrt: 0.00258  | loss_unl: 0.00802  | learning_rate: 0.00036\n",
      "OA: 0.9256  | AA:  0.9176  | Kappa:  0.9154  | Time: 53.4\n",
      "[1800,  3601] loss: 0.0074929  | loss_wrt: 0.00522  | loss_unl: 0.01046  | learning_rate: 0.00036\n",
      "OA: 0.9286  | AA:  0.9255  | Kappa:  0.9186  | Time: 53.4\n",
      "[1850,  3701] loss: 0.0560631  | loss_wrt: 0.00492  | loss_unl: 0.00985  | learning_rate: 0.00036\n",
      "OA: 0.9212  | AA:  0.9072  | Kappa:  0.9104  | Time: 53.6\n",
      "[1900,  3801] loss: 0.0163607  | loss_wrt: 0.00433  | loss_unl: 0.00974  | learning_rate: 0.00036\n",
      "OA: 0.9269  | AA:  0.9217  | Kappa:  0.9169  | Time: 53.4\n",
      "[1950,  3901] loss: 0.0189617  | loss_wrt: 0.00559  | loss_unl: 0.00807  | learning_rate: 0.00036\n",
      "OA: 0.9092  | AA:  0.8973  | Kappa:  0.8964  | Time: 54.2\n",
      "[2000,  4001] loss: 0.0059086  | loss_wrt: 0.00203  | loss_unl: 0.00622  | learning_rate: 0.00036\n",
      "OA: 0.9249  | AA:  0.9239  | Kappa:  0.9146  | Time: 53.7\n",
      "Finished Training\n",
      "model saved\n",
      "[0.92307692 0.95963756 0.85531915 0.89054726 0.8540146  0.97419355\n",
      " 1.         0.99507389 1.         0.92251816 0.9281265  0.93650794\n",
      " 0.99425287 0.9172093  0.91768293 0.62025316]\n",
      "0.9257175660160735 0.9180258623112929 0.9155041592014832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_evalnet_ss_v2.py:245: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_start = time.clock()\n",
      "train_evalnet_ss_v2.py:304: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n",
      "train_evalnet_ss_v2.py:334: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_train_end = time.clock()\n",
      "train_evalnet_ss_v2.py:356: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  time_test_end = time.clock()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "===> Try resume from checkpoint\n",
      "===> Load last checkpoint data\n",
      "torch.Size([256, 200, 31, 31]) torch.Size([256, 200, 31, 31])\n",
      "=> all bands acc: 0.405\n",
      "ep  50 / 2000\n",
      "W_0 Ep: 50 | Ep_r: -5.43 | loss:0.405 | 100 bands | 7.6s\n",
      "ep  100 / 2000\n",
      "W_0 Ep: 100 | Ep_r: -4.93 | loss:0.414 | 100 bands | 4.4s\n",
      "ep  150 / 2000\n",
      "W_0 Ep: 150 | Ep_r: -4.44 | loss:0.394 | 100 bands | 4.4s\n",
      "ep  200 / 2000\n",
      "W_0 Ep: 200 | Ep_r: -4.24 | loss:0.402 | 100 bands | 4.4s\n",
      "ep  250 / 2000\n",
      "W_0 Ep: 250 | Ep_r: -4.03 | loss:0.402 | 100 bands | 4.4s\n",
      "ep  300 / 2000\n",
      "W_0 Ep: 300 | Ep_r: -3.74 | loss:0.384 | 100 bands | 4.4s\n",
      "ep  350 / 2000\n",
      "W_0 Ep: 350 | Ep_r: -3.44 | loss:0.384 | 100 bands | 4.4s\n",
      "ep  400 / 2000\n",
      "W_0 Ep: 400 | Ep_r: -3.31 | loss:0.375 | 100 bands | 4.4s\n",
      "ep  450 / 2000\n",
      "W_0 Ep: 450 | Ep_r: -3.09 | loss:0.372 | 100 bands | 4.5s\n",
      "ep  500 / 2000\n",
      "W_0 Ep: 500 | Ep_r: -3.03 | loss:0.377 | 100 bands | 4.6s\n",
      "ep  550 / 2000\n",
      "W_0 Ep: 550 | Ep_r: -3.10 | loss:0.392 | 100 bands | 4.6s\n",
      "ep  600 / 2000\n",
      "W_0 Ep: 600 | Ep_r: -2.97 | loss:0.376 | 100 bands | 4.6s\n",
      "ep  650 / 2000\n",
      "W_0 Ep: 650 | Ep_r: -2.83 | loss:0.388 | 100 bands | 4.6s\n",
      "ep  700 / 2000\n",
      "W_0 Ep: 700 | Ep_r: -2.99 | loss:0.349 | 100 bands | 4.7s\n",
      "ep  750 / 2000\n",
      "W_0 Ep: 750 | Ep_r: -2.94 | loss:0.366 | 100 bands | 4.7s\n",
      "ep  800 / 2000\n",
      "W_0 Ep: 800 | Ep_r: -2.96 | loss:0.355 | 100 bands | 4.7s\n",
      "ep  850 / 2000\n",
      "W_0 Ep: 850 | Ep_r: -2.96 | loss:0.360 | 100 bands | 4.8s\n",
      "ep  900 / 2000\n",
      "W_0 Ep: 900 | Ep_r: -2.92 | loss:0.380 | 100 bands | 4.7s\n",
      "ep  950 / 2000\n",
      "W_0 Ep: 950 | Ep_r: -2.61 | loss:0.365 | 100 bands | 4.6s\n",
      "ep  1000 / 2000\n",
      "W_0 Ep: 1000 | Ep_r: -2.45 | loss:0.368 | 100 bands | 4.6s\n",
      "ep  1050 / 2000\n",
      "W_0 Ep: 1050 | Ep_r: -2.45 | loss:0.350 | 100 bands | 4.7s\n",
      "ep  1100 / 2000\n",
      "W_0 Ep: 1100 | Ep_r: -2.50 | loss:0.358 | 100 bands | 4.7s\n",
      "ep  1150 / 2000\n",
      "W_0 Ep: 1150 | Ep_r: -2.27 | loss:0.353 | 100 bands | 4.7s\n",
      "ep  1200 / 2000\n",
      "W_0 Ep: 1200 | Ep_r: -2.31 | loss:0.347 | 100 bands | 4.8s\n",
      "ep  1250 / 2000\n",
      "W_0 Ep: 1250 | Ep_r: -2.29 | loss:0.366 | 100 bands | 4.8s\n",
      "ep  1300 / 2000\n",
      "W_0 Ep: 1300 | Ep_r: -1.99 | loss:0.358 | 100 bands | 4.7s\n",
      "ep  1350 / 2000\n",
      "W_0 Ep: 1350 | Ep_r: -1.76 | loss:0.344 | 100 bands | 4.6s\n",
      "ep  1400 / 2000\n",
      "W_0 Ep: 1400 | Ep_r: -1.61 | loss:0.360 | 100 bands | 4.7s\n",
      "ep  1450 / 2000\n",
      "W_0 Ep: 1450 | Ep_r: -1.69 | loss:0.340 | 100 bands | 4.8s\n",
      "ep  1500 / 2000\n",
      "W_0 Ep: 1500 | Ep_r: -1.56 | loss:0.340 | 100 bands | 4.7s\n",
      "ep  1550 / 2000\n",
      "W_0 Ep: 1550 | Ep_r: -1.85 | loss:0.357 | 100 bands | 4.9s\n",
      "ep  1600 / 2000\n",
      "W_0 Ep: 1600 | Ep_r: -1.68 | loss:0.351 | 100 bands | 4.8s\n",
      "ep  1650 / 2000\n",
      "W_0 Ep: 1650 | Ep_r: -1.87 | loss:0.326 | 100 bands | 4.9s\n",
      "ep  1700 / 2000\n",
      "W_0 Ep: 1700 | Ep_r: -2.03 | loss:0.337 | 100 bands | 4.9s\n",
      "ep  1750 / 2000\n",
      "W_0 Ep: 1750 | Ep_r: -2.19 | loss:0.352 | 100 bands | 5.0s\n",
      "ep  1800 / 2000\n",
      "W_0 Ep: 1800 | Ep_r: -1.99 | loss:0.363 | 100 bands | 4.9s\n",
      "ep  1850 / 2000\n",
      "W_0 Ep: 1850 | Ep_r: -1.81 | loss:0.354 | 100 bands | 4.8s\n",
      "ep  1900 / 2000\n",
      "W_0 Ep: 1900 | Ep_r: -1.64 | loss:0.363 | 100 bands | 4.8s\n",
      "ep  1950 / 2000\n",
      "W_0 Ep: 1950 | Ep_r: -1.22 | loss:0.346 | 100 bands | 4.7s\n",
      "r_max, 0.33915774204797344\n",
      "Done\n",
      "time :189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-22 16:32:29.329708: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\n",
      "2020-03-22 16:32:29.332579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \n",
      "name: GeForce RTX 2080 Ti major: 7 minor: 5 memoryClockRate(GHz): 1.545\n",
      "pciBusID: 0000:65:00.0\n",
      "totalMemory: 11.00GiB freeMemory: 8.69GiB\n",
      "2020-03-22 16:32:29.332740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\n",
      "2020-03-22 16:32:29.768135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-03-22 16:32:29.768236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \n",
      "2020-03-22 16:32:29.768284: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \n",
      "2020-03-22 16:32:29.768484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8367 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:65:00.0, compute capability: 7.5)\n",
      "WARNING:tensorflow:From A3C_main.py:205: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From A3C_main.py:177: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "cuda:0\n",
      "Start training...\n",
      "[25,   101] loss: 1.2855594  | loss_wrt: 0.12753  | loss_unl: 0.14679  | learning_rate: 0.00100\n",
      "OA: 0.8936  | AA:  0.7352  | Kappa:  0.8789  | Time: 16.5\n",
      "[50,   201] loss: 0.1455527  | loss_wrt: 0.06401  | loss_unl: 0.07100  | learning_rate: 0.00090\n",
      "OA: 0.9490  | AA:  0.9047  | Kappa:  0.9420  | Time: 16.3\n",
      "[75,   301] loss: 0.0584793  | loss_wrt: 0.02752  | loss_unl: 0.03716  | learning_rate: 0.00081\n",
      "OA: 0.9620  | AA:  0.9236  | Kappa:  0.9567  | Time: 16.3\n",
      "[100,   401] loss: 0.0316908  | loss_wrt: 0.01855  | loss_unl: 0.02689  | learning_rate: 0.00073\n",
      "OA: 0.9641  | AA:  0.9179  | Kappa:  0.9591  | Time: 16.3\n",
      "[125,   501] loss: 0.0389101  | loss_wrt: 0.04151  | loss_unl: 0.05079  | learning_rate: 0.00066\n",
      "OA: 0.9549  | AA:  0.9088  | Kappa:  0.9486  | Time: 16.3\n",
      "[150,   601] loss: 0.0325327  | loss_wrt: 0.01353  | loss_unl: 0.01986  | learning_rate: 0.00059\n",
      "OA: 0.9680  | AA:  0.9267  | Kappa:  0.9635  | Time: 16.3\n",
      "[175,   701] loss: 0.0152836  | loss_wrt: 0.00821  | loss_unl: 0.01484  | learning_rate: 0.00053\n",
      "OA: 0.9692  | AA:  0.9292  | Kappa:  0.9649  | Time: 16.3\n",
      "[200,   801] loss: 0.0110958  | loss_wrt: 0.00718  | loss_unl: 0.01159  | learning_rate: 0.00048\n",
      "OA: 0.9696  | AA:  0.9210  | Kappa:  0.9653  | Time: 16.3\n",
      "[225,   901] loss: 0.0088529  | loss_wrt: 0.00724  | loss_unl: 0.00900  | learning_rate: 0.00043\n",
      "OA: 0.9680  | AA:  0.9256  | Kappa:  0.9635  | Time: 16.3\n",
      "[250,  1001] loss: 0.0199029  | loss_wrt: 0.03669  | loss_unl: 0.03991  | learning_rate: 0.00039\n",
      "OA: 0.9386  | AA:  0.8267  | Kappa:  0.9300  | Time: 16.3\n",
      "[275,  1101] loss: 0.0209499  | loss_wrt: 0.00940  | loss_unl: 0.01181  | learning_rate: 0.00035\n",
      "OA: 0.9692  | AA:  0.9246  | Kappa:  0.9650  | Time: 16.3\n",
      "[300,  1201] loss: 0.0089704  | loss_wrt: 0.00535  | loss_unl: 0.00858  | learning_rate: 0.00031\n",
      "OA: 0.9701  | AA:  0.9264  | Kappa:  0.9660  | Time: 16.3\n",
      "[325,  1301] loss: 0.0065131  | loss_wrt: 0.00402  | loss_unl: 0.00688  | learning_rate: 0.00028\n",
      "OA: 0.9710  | AA:  0.9279  | Kappa:  0.9669  | Time: 16.3\n",
      "[350,  1401] loss: 0.0054270  | loss_wrt: 0.00314  | loss_unl: 0.00547  | learning_rate: 0.00025\n",
      "OA: 0.9713  | AA:  0.9277  | Kappa:  0.9673  | Time: 16.3\n",
      "[375,  1501] loss: 0.0045749  | loss_wrt: 0.00281  | loss_unl: 0.00471  | learning_rate: 0.00023\n",
      "OA: 0.9707  | AA:  0.9278  | Kappa:  0.9667  | Time: 16.3\n",
      "[400,  1601] loss: 0.0040305  | loss_wrt: 0.00248  | loss_unl: 0.00453  | learning_rate: 0.00021\n",
      "OA: 0.9708  | AA:  0.9206  | Kappa:  0.9668  | Time: 16.5\n",
      "[425,  1701] loss: 0.0034006  | loss_wrt: 0.00254  | loss_unl: 0.00371  | learning_rate: 0.00019\n",
      "OA: 0.9710  | AA:  0.9271  | Kappa:  0.9669  | Time: 16.6\n",
      "[450,  1801] loss: 0.0030532  | loss_wrt: 0.00207  | loss_unl: 0.00239  | learning_rate: 0.00017\n",
      "OA: 0.9712  | AA:  0.9238  | Kappa:  0.9672  | Time: 16.4\n",
      "[475,  1901] loss: 0.0027185  | loss_wrt: 0.00197  | loss_unl: 0.00309  | learning_rate: 0.00015\n",
      "OA: 0.9715  | AA:  0.9214  | Kappa:  0.9676  | Time: 16.3\n",
      "[500,  2001] loss: 0.0024456  | loss_wrt: 0.00157  | loss_unl: 0.00238  | learning_rate: 0.00014\n",
      "OA: 0.9715  | AA:  0.9237  | Kappa:  0.9676  | Time: 16.3\n",
      "Finished Training\n",
      "(8710, 2)\n",
      "[0.94871795 0.99588138 0.95602837 0.93034826 0.87347932 0.97741935\n",
      " 1.         0.97783251 0.64705882 0.97941889 0.97700048 1.\n",
      " 0.98850575 0.99162791 0.99085366 0.5443038 ]\n",
      "0.9715269804822043 0.9236547778097066 0.9675632522437665\n",
      "(21025, 2)\n"
     ]
    }
   ],
   "source": [
    "#count results\n",
    "data_name = \"Indian_pines\"\n",
    "###################################\n",
    "from evaluate_ss import RET\n",
    "results =[]\n",
    "for i in range(5):\n",
    "    !python get_prefile_ss.py --data_name \"Indian_pines\" --pt 0.05 --pv 0.10\n",
    "    !python train_evalnet_ss_v2.py --data_name \"Indian_pines\" \n",
    "    !python A3C_main.py --data_name \"Indian_pines\" --num_band_selection 100 --eval_net_path \"./checkpoint/Indian_pines.t7\" -- out_put_path \"./output/Indian_pines\"\n",
    "    model = RET(data_name)\n",
    "    results.append(model.results)\n",
    "import numpy as np\n",
    "results = np.array(results)\n",
    "avarage = results.mean(axis=0)*100\n",
    "std = results.std(axis=0)*100\n",
    "avg = [\"%.1f±%.1f\"%(avarage[i],std[i])for i in range(avarage.shape[0])]\n",
    "import xlwt\n",
    "import time\n",
    "#创建一个Workbook对象，相当于创建了一个Excel文件\n",
    "book=xlwt.Workbook(encoding=\"utf-8\",style_compression=0)\n",
    "sheet = book.add_sheet(data_name, cell_overwrite_ok=True)\n",
    "clo_0 = [\"OA\",\"AA\",\"Kappa\"]+list(range(16))\n",
    "row_o = [data_name]+list(range(5))+[\"avg\"]\n",
    "for i in range(len(row_o)):\n",
    "    sheet.write(0, i,row_o[i])\n",
    "for j in range(len(clo_0)):\n",
    "    sheet.write(j+1, 0,clo_0[j])\n",
    "for i in range(len(results)):\n",
    "    for j in range(len(results[0])):\n",
    "        sheet.write(j+1, i+1,results[i][j])\n",
    "for j in range(len(results[0])):\n",
    "    sheet.write(j+1,6,avg[j])\n",
    "book.save(data_name+\"_BSRL_\"+avg[0]+'.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
